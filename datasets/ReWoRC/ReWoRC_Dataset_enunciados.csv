Documento;Enunciado
2001 - hats.pdf;HATS was developed to explore transformation-based software development. Transformations are a wellknown formal method for developing software. The HATS-GUI is intended to provide HATS users with an intuitive graphical interface to the HATS system. HATS is publicly available, and the HATS-GUI will be delivered with HATS. The purpose of HATS is to perform program transformations in a provably correct fashion. This enables users to construct software by transforming a target program, or simply a target, written in an abstract language to a transformed output program written in a more concrete language. By demonstrating that the transformations preserve the semantics of the target program, the user has assurance that the transformed program is correct. HATS applies a sequence of transformations to a target program by following instructions in a transformation language program. A transformation language program consists of sequences of transformation instructions and constructs to control the application of transformations.
2001 - beyond.pdf;"BEYOND is a macro-project focused on improving user interfaces. This document presents some projects with their individual problem areas and domains.
1. Philips DVS aims at developing a prototype of an authoring tool for visualisation, specification, design, code generation of user interfaces for consumer products, with particular emphasis on screen based user interfaces and control, and taking into account the constraints of the consumer world as mentioned above.
The high level requirements for this authoring tool are:
- The authoring tool should allow easy modification of the behaviour of user interfaces.
- The authoring tool should support easy development of adaptive user interfaces.
- The authoring tool should allow the functional requirements specification of thenext generation of consumer products to be developed in a much faster and efficient manner.
2.  In other project, we desire to have an ‘intelligent’ software layer having the most important feature that the User Interface is User Definable. The software structure of the firmware should be suitable for adding a ‘UIinterpreter’ (to interprete and visualize the UI code generated by the UI Editor; so a very important component in this project). 
To make our UI-Editor complete, it must have a simulation module incorporated so we can try the complete system off-line on our development computer before loading the generated code into the Vector System."
2003 - qheadache.pdf;"The product is a computerized game that displays an interface used to solve a specific headache. The product runs as a standalone
application. Its user interface uses menus, graphics and sounds. The product requires the use of a keyboard and a mouse to interface with the
user. It requires a graphical display of at least 800*600 resolution. The users consist of anyone who wants to play a simple game who knows how to
operate a computer, with a beginning level player starting at age 8, up through an advanced level player who could be an adult."
2005 - triangle.pdf;"Triangular Games is a stand-alone software application that is meant to realize games described in the article “Games on Triangulations”. A triangulation game is a strategic game played on a triangular grid, typically by two players. The objective of the game is to create a path that connects three sides of the triangular grid. Players take turns placing lines or dots on the grid, with the goal of preventing their opponent from completing a path while also trying to complete their own. The software makes it possible to play multiple triangulation games.  The games may be played alone or
against another person, depending on the type of game. A graphical user interface will be shown to the user. This user interface is mainly mouse controlled but may also be used with a keyboard as well.
By default, the system will be able to implement three different games, namely constructing, transforming and marking. New games may be added to the software easily without the need to modify the code of the original application. These added games will be automatically selectable through the application’s graphical user interface. The software will be implemented using the Java-platform. This makes it possible to run the application on multiple different environments without any modification to the code. "
1999 - multi-mahjong.html;"MultiMahjong is a product consisting of two programs - a MultiMahjongServer and a MultiMahjongClient. This Server/Client architecture will allow up to 4 players to play Mahjong against each other over a TCP/IP network. The MultiMahjongClient program will also allow 1 player to play in a stand-alone mode.
As any game of Mahjong requires 4 players to play, and there may not be 4 people available for a network game, the game will allow users to choose enough computer opponents to make up the required 4 players. In a single player game, the user will play against 3 computer opponents.
To play the game, users will use the MultiMahjongClient. The MultiMahjongServer is to reside on a TCP/IP server and will communicate with MultiMahjongClients."
2005 - phin.pdf;This document describes the Public Health Information Network (PHIN) functional requirements for systems implemented to participate in the management of outbreaks and other health events. Outbreak Management (OM) is the PHIN functional area intended to support the needs of investigation, monitoring, management, analysis, and reporting of a health event or act of bioterrorism. OM should aid in the collection and analysis of data to support identifying and containing the health event. OM systems should be configurable to meet the needs of different types of health events, and capture data related to cases, contacts, investigations, exposures, relationships, clinical and environmental specimens/samples, laboratory results, vaccinations and treatments, travel history, and conveyance information. The application should also allow for new objects to be defined and created during the course of an investigation. Central to the functionality of a system supporting OM is the ability to collect data related to cases and exposures and to create traceable links between all appropriate entities. By tracing the mechanism of transmission and identifying the source of the health event, the appropriate response staff can more effectively contain the event. Systems supporting OM should also be integrated with the systems supporting early event detection, countermeasure administration, laboratory, and surveillance to achieve the primary goal of managing the response to and mitigating the effects of an event.
2005 - clarus low.pdf;"The Clarus Initiative is essentially a plan to create a “network of networks” — much like the Internet — for surface transportation environmental data. While the Internet is an interconnection of computer networks, Clarus will be an interconnection of  environmental (weather, pavement, and water level condition) data collection networks. Each of the weather networks will function autonomously; they will collect information and disseminate it internally without direction or dependence on Clarus.  Each participating weather network’s connection to Clarus will add two new possible modes of functionality. First, the participants will be able to share collected environmental data with Clarus. Second, participants will be able to receive environmental data collected by Clarus. The primary recipients of this data will be weather service providers, but any Clarus participants would be able to receive data if they so chose. This concept of autonomous data sharing is comparable to the World Wide Web layer of the Internet, where organizations can publish information on web pages, or browse and download information published by other organizations on the web. Ownership of the data is retained by the organization that provided the data to Clarus, and the provider organization can restrict the dissemination of the data through data sharing agreements with the Clarus program.
The Clarus system will add a third mode of functionality, which might be called “meta-librarian.” The Clarus system will collect, organize, and quality check the environmental data to be published by the system. The data will be collected from the participants, organized by location and type of data, and quality flags will be added. When this is done, the data will be published to the Service Providers and other participant/consumers in Clarus.
The principal interfaces that will be critical to Clarus are the interface between Clarus and the participating collectors, and the interface between Clarus and the participating service providers. MADIS, for example, uses NetCDF files as a standard interchange format. While the service provider interface is completely within the control of the Clarus Initiative, the interface(s) to the collectors may be influenced by what interfaces these systems can support.
While the participants may want to access the network through “a one-stop Internet portal for all surface transportation weather and pavement related observations”, there is no requirement that the system be a single centralized system. Designers are free to explore centralized and de-centralized architectures so long as the interfaces with participants give the appearance of a “one-stop” portal.
The issues of data retention and archive are also not explicitly addressed. While some data retention is likely to be necessary to support the quality checking function and the publication function, there is a clear recognition that as the data age, they lose value to all but climatological investigators and other researchers. This phase of development does not include directly archiving the large volume of environmental data in Clarus. Considering the technical scope of such an effort, archiving may be externalized or be deferred until the Clarus network is operational and proven.
The Clarus system will collect data from contributing members, organize and quality check the data, and then publish the data for use by service providers and other members of the network."
2009 - inventory 2.0.pdf;The Inventory Management System is an application designed to allow the Construction Junction staff to create, maintain and view the contents and value of its inventory of items in a categorized way. It also facilitates the process of receiving items into the Construction Junction inventory via the drop-off, pick-up and deconstruction donation processes so that items can be traced from donation through sale. It also integrates with the QuickBooks Point of Sale retail management software currently in use by Construction Junction as well as the organization's website.
2008 - vub.pdf;"The product will support the functionality of a PMS (Publication Managemente System), which can be accessed by command line and through a web browser (following the W3C XHTML-standards [3]). The PMS will manage a database with bibliographical information and have the possibility to save the entire text of a publication in pdf and postscript. It will be able to automatically retrieve bibliographical information (like author, title, etc.) out of the complete text of a publication and will provide the possibility to correct this manually, if the obtained information is incorrect or insufficient. The concept ‘author’ (name, first name, institute. . . ) will be explicitly known by the system and the user will be able to manually indicate that references like ‘D. Vermeir’ and ‘Dirk Vermeir’ refer to the same author. The possibility will also be provided to receive a ‘bulk update’. The system will support several types of accessing, including accessing of the contents of a publication, if the complete text (or only the abstract) is available and it will also support access control. The PMS will rely on a database and a web server, which can be accessed by a web browser and by command line.
There will be multiple types of users:
• A Guest is an anonymous user that is not connected to the VUB-network. Therefore he/she will only be allowed to log in or register.
• A VUB-Network User is connected to the VUB-network, but is not logged in. The PMS will recognize them by their IP-address. They can access the database, search for publications and download them.
• A Member is a user that has logged into the PMS and whose account only allows him to search for publications and download them.
• A Publisher is a logged in user that can search for, upload and download publications.
• A Moderator has the same prerequisites and available functions as a Member, extended with the authority to edit and delete publications.
• An Administrator has all the possibilities of a moderator extended with the responsibility for the technical aspects of the PMS. He/She also has the possibility to up or downgrade the accounts of users and in extreme cases he can even expel registered users.
Accessing the PMS from outside the VUB-network is only possible for logged in users. Person(s) that are not logged in and/or connected to the VUB-network will only have Guest privileges. To be able to log in a user will have to register an account. This requires that the user provides their first and last name, a password and a valid e-mail address. If a user is accepted, he/she will receive a validation mail and by that way he/she will be able to confirm
the registration of the user account. Any user will be able to search for publications by title, author(s), institute,. . . Also will the user be able to specify that ‘D. Vermeir’ and ‘Dirk Vermeir’ refer to the same author and that ‘VUB’ or ‘Vrije Universiteit Brussel’ refer to the same institute"
2005 - znix.pdf;"Project ZNIX envisions a world which leaves behind a one that users manage information by mastering software applications. Emphasis in this approach is on information and its semantics. It seeks to make meaningful information accessible to users in ways they themselves declare to be logical. Product Functions:
• Provide a centralized archive for user’s information.
• Provide hierarchical model for managing the archived information. Hierarchies maybe inheritance based, association based or based on any other type of relationship conceived by the user.
• Allow the user to add, remove, modify or back up (to removable storage devices) arbitrary pieces of information without disrupting the hierarchy.
• Assist the user in building up his information hierarchy by automating such tasks as data capturing and categorizing.
• Provide a simple API for developing ZNIX-aware client applications.
The browser GUI SHOULD be designed such that even casual users could easily manipulate their information with little or no training. It is expected that the bulk of the ZNIX user-base would be home users, managerial staff, executives, and researchers who are likely to possess only basic IT skills. The system design MUST be subjected to the following constraints: Hardware: Intel Pentium III or compatible 1-GHz PC with 256 megabytes of RAM.  "
2003 - pnnl.pdf;"The automated diagnostic tool detects and identifies faults in chillers and cooling tower subsystems ofHVAC units using sensed data acquired from the unit, unit specifications, unit installation andconfiguration data, and unit operation data (such as schedules). The tool is a software product that will be utilized primarily by building operators and facilities managers and only secondarily by HVAC service technicians, energy service providers, and operation supervisors. Building operators will use the tool to monitor units for which they are responsible, perhaps monitoring from a central control room within the building. Service technicians will utilize the product on site during repair and maintenance visits or off site between visits. Energy service providers, responsible for a number of customers and facilities, will use the product to monitor a number of units remotely, possibly in many different buildings, checking for inefficiencies and problems requiring dispatch of service personnel. Finally, building operator supervisors will use the tool to guide decisions on the assignment of operators and prioritization of work. The tool will provide the user with a visual indication of faults, descriptive information concerning the faults and their causes, and suggested corrective actions. The tool will store the results of diagnostics for subsequent retrieval and use. The software require ments described in this document are applicable to HVAC systems and associated
subsystems. Such subsystems can include chillers, cooling towers, and boilers. However, the initial version of the tool will focus on diagnostics for chillers and cooling towers only. The tool will automate diagnostic processes hitherto performed through a visual analysis of graphical data by a human expert. The data-preprocessing component obtains data describing the subsystem under diagnosis and reduces, filters, and otherwise prepares the data for input to the diagnostic component. This data includes sensed data, e.g., temperatures, pressures, electrical current, machine state, etc., as well as fixed data describing the characteristics of the subsystem under diagnosis, for example, specifications and design information, operating characteristics and set points, etc. The data may be processed through averaging, trending, or other statistical analysis. Sensed data can originate from data acquisition hardware either in real time or at some arbitrary time after acquisition. Fixed data will generally be compiled prior to operation of the diagnostic tool and be obtained from permanent storage when needed. The diagnostic component will detect and identify faults in the operation of HVAC subsystems based on sensed and fixed data input from the data-preprocessing component. The output component will display and record results output from the diagnostic component. The results of the diagnostics will be displayed to the user in a simple, graphical and textual format. The results will also be stored to permanent storage for subsequent retrieval and analysis."
2007 - eirene fun 7.pdf;"An EIRENE network is a railway telecommunications network, based on the ETSI GSM standard, which complies with all related mandatory requirements specified in the EIRENE FRS and SRS. An EIRENE network may also include optional features and these shall then be implemented as specified in the EIRENE FRS and SRS. The EIRENE network excludes terminals. To meet the functionality and performance requirements of EIRENE, the following system services are required: voice services:
− voice services, such as point-to-point calls public emergency calls...
− data services, such as text message bearer service, bearer service for general data applications...
− call related services, such as auto answer system, call supervisory indications, charging information...railway specific applications:
− railway specific applications: support for functional addressing by train, engine or coach number or functional number,  call specific persons depending upon user location... 
− direct mode facility for local set-to-set operation without network infrastructure;
− railway specific features: set-up of urgent or frequent calls through single keystroke or similar; display of functional identity of calling/called party...
Three distinct mobile radio types are required, based on the type of role they will perform and the environment in which they will operate, as follows: (I)
a) Cab radio – for use by the driver of a train and/or by other on-train systems, eg ERTMS/ETCS;
b) General purpose radio – for general use by railway personnel;
c) Operational radio – for use by railway personnel involved in train operations such as shunting and trackside maintenance."
2004 - rlcs.pdf;RLCS means Reversible Lanes Control System. The RLCS Application will allow an operator to view system status and issue commands to change device status as well as configure the system and generate reports. The five major functions of the RLCS application software are a Graphical User Interface (GUI), Process Control and Monitoring, Sequencing, Data Processing and Security, and Reporting. The user will operate the RLCS Application software using a graphical user interface, RLCS application will seamlessly interface and control hardware devices. The RLCS will provide access to system status data, to external systems through a firewall. This will be a one way data transfer to a computer outside of the RLCS network and making it available there for public use. The transfer will occur every 30 seconds. A one way serial data transfer will also be provided. RLCS workstations and controllers will reside on a private network to communicate field device information. 
2007 - water use.pdf;"The vision of the Water Use Tracking (WUT) System, as captured during the Executive Stakeholders Workshop, defines the system as: “A GIS-based system that allows District employees and external customers to spatially and temporally track and analyze key Regulatory and Resource Management data.” This system will support Southwest Florida Water Management District’s (SWFWMD) activities defined in the Southern Water Use Caution Area (SWUCA) Management Plan and to validate and assess the results of the SWUCA II Rules. Although this system is being built to support the efforts within the SWUCA, it will support the same functionality for anywhere within the District. Rules are in the process of being implemented in support of the SWUCA Recovery Strategy that has no current, automated way of being validated or assessed in their fulfillment of the needs of the plan. One problem is no formal or consistent system exists at the District (manual or automated) to comprehensively track and analyze geographic and temporal trends in permitted and actual water uses within the SWUCA. Currently, tracking of spatial and temporal trends in permitted and actual water uses is done using manual and semi-automated methodologies by a number of groups in the District.
Examples of current work include monthly summary reports of permitted pumpage developed by the Technical Services Department, annual water use estimates developed by the Conservation Projects Department, and ad hoc maps of permitted pumpage developed by the Mapping and GIS Section (MGIS). This approach is staff time intensive, and since data sources and methodologies vary between different groups conducting these analyses, it may lead to inconsistent or apparently conflicting results. This is further complicated by the fact that current database management systems and data collection activities were not specifically designed to support these types of activities. The result is that the current system does not adequately support the types of analyses required for successful implementation of the SWUCA Management Plan. The WUT Project will provide software for several different customer types. The system will assist in the WUP review process. The system will be used to track and analyze long-term trends in permitted and actual water use and to assist in identifying underlying causes for these trends (land use change, socio-economic conditions, environmental factors, etc.). The system will provide tools to assist in the quality control/quality assurance of WUP data. – The system will provide information that can be used to assist in the calibration of ground water models. The system will also provide information on WUPs that can support the establishment and monitoring of Minimum Flows and Levels (MFL). In addition, the system will provide information that assists in the development of estimated water use.  The system will provide tools to assist in studies analyzing impacts of changing demographics and economic conditions on water use within the SWUCA. The system will provide standard reports that are published as hardcopy or web-accessible documents. Web accessible maps and documents could be interactive, allow users to zoom, pan, and query areas of interest. "
2003 - agentmom.pdf;"*agentMom project will be a framework that provides reusability of agent’s communication. It is implemented in Java and provides the basic building blocks for building agents, conversations between agents, and the message that are passed in the conversations. The system will:
- Enable agents to broadcast a message to all the agents within the same local network.
- Enable agents to multicast a message to all the agents within the same multicast address.
- Enable agents to unicast a message to other agents within organization.
- Allow agents to choose among unicast, multicast and broadcast communication.
- Allow agents to join and leave multicast group.
- Provide message encryption and decryption techniques for secured communication.
- Allow agents to choose to encrypt or not to encrypt message"
2010 - digital home 1.3.pdf;The Digital Home (DH) system, for the purposes of this document, is a system that will allow a home user to manage devices that control the environment of a home. The user communicates through a personal web page on the DigitalHome web server or on a local home server. The DH web server communicates, through a home wireless gateway device, with the sensor and controller devices in the home. The product is based on the Digital Home High Level Requirements Definition [HLRD 2010] is intended as a prototype, which will allow business decisions to be made about future development of a commercial product. The scope of the project will be limited to the management of devices which control temperature, humidity, security, and power to small appliances and lighting units, through the use of a web-ready device.  The Digital Home components consist of household devices (e.g., a heating and air conditioning unit, a security system, and small appliances and lighting units, etc.), sensors and controllers for the devices, communication links between the components, and a computer system, which will manage the components. 
2005 - microcare.pdf;"Design a voucher Management system. The voucher management system VMS is designed to atomize the process of Voucher Management Unit (VMU) to minimize the manual process to maximize the quality of the project to understand the progress and timely out come of the project to take necessary steps by the MSIU Admin team to plan for the future and to increase the quality of the STD voucher service. The system will also control the existence of fraud in claims and will help the service provider to reach their payments in time without delay. The other features and details of system will be explained in below sections in the document.

The voucher management system is subdivided into following modules to make the system easy for understanding, developing, testing and to implement.
1. Voucher Creation / Preparation 2. Marketing / Sales 3. Claim Entry / Processing 4. Voucher Sales Return 5. Client Feed back 6. Reports (Standard and Customized) 7. Security and User Privileges.

• The VMU will create the vouchers and sell it to clients through distributors.
• The distributor will submit the sales details back to the VMU.
• Each voucher should have two portions with three tear off voucher slips each for Client and Partner.
• The client and/or the partner will choose the service provider and will get treatment.
 • First visit is called as Consultation and if the patient is not cured then they can go for first follow up and second follow up,
• If the patient is not cured then the doctor will refer the patient to some other Hospitals the hospital may be another VSP or any other.
• Each visit details (including Diagnosis, Lab Test and Drugs) of the patient is called a claim,
• The VSP will submit the claim to VMIU field office to enter those into the database, 
• The filed office will validate the claim form manually and through system,
• If any of mandatory information is missed or any false information is existing then the field office will reject the claim back to VSP and the system will keep those claim in a quarantine area.
• The quarantined forms will be sent back to the VSP for verification, if the VSP returns the claim with satisfactory details, the claims will be entered on to the system, in the following month’s batch.
• Based on the payment terms agreed by VSP, the field office will generate BiMonth or Monthly financial and medical report and send it to MSIU Admin team to arrange the payments for the VSP.
• To understand the satisfaction of client the MSIU Admin team will get client feedback from some of the clients and send those documents to field office to enter those into database."
2010 - split merge.pdf;"PDF Split and Merge is a FOSS tool that can split, merge and manipulate PDF documents. It provides a graphical Interface (GUI) and a shell Interface (Console). It is available in two versions, basic and enhanced, both are open source. The GUI provides the user with all the functionality needed to handle a PDF file (or more files together). The functionalities are distributed in plugins. Each plugin performs a specific function and loads in the main GUI. In the basic version, the GUI contains six plugins:
− Alternate Mix
− Merge/Extract
− Rotate
− Split
− Visual document composer
− Visual reorder
The Console is a command-line application. It’s the core application and it provides both the
enhanced and the basic features for pdf manipulation."
2007 - e-store.pdf;The system is an e-store which permits to configure and sell products. The store provides comprehensive product details, product Categorizations, Search facility, customer profile with personalization options, customer support, shopping cart facility, mulitple shipping methods, Online tracking of shipments, Tax Calculations, multiple payment methods and detailed sitemap. It also allows online change or cancellation of order, Online Product reviews and ratings, e-mail confirmation and it offers online promotions, rewards and financing options.
2003 - tachonet.pdf;The tachograph is the device that records driving times and rest periods as well as periods of other work and availability taken by the driver of a heavy vehicle. For the proper implementation of the regulations concerning the tachograph, it is essential that every driver holds only one valid driver card. Therefore, Member States must ensure the uniqueness of the driver card they issue by exchanging information with the other Member States. The TACHOnet is a telematic network in operation across the EU to allow an automated exchange of information between Member States. TACHOnet aims for centralized monitoring of professional drivers.
2010 - mashboot.pdf;"Mashbot is a web service for managing a company’s presence on social networks. One goal of Mashbot is to unify the interfaces of a multitude of social networks, allowing users to learn a standardized interface and more easily cope with the flood of new social network platforms. The initial focus will be on scheduled marketing campaigns utilizing social media. However, this may expand to include customer service functionality, management of more traditional campaigns such as direct mail,
trade shows and other events, or user-created campaign classes. The first objective is to develop and release a small open source platform to provide a service agnostic facade API bundling common operations in widely used services (e.g., Facebook, Flickr, Twitter, Wordpress, or YouTube). This platform will provide a plugin-based architecture for abstracting myriad services behind a single facade, based upon content types provided in common data models. Mashbot combines several components to provide required functionality: 
• Authentication Mashbot will allow the use of external authentication modules for user login. Mashbot
will also provide an internal authentication mechanism in case an external module is unavailable.
• Campaign Manager Web Client Mashbot has an interface for a web client which processes user
commands to interact with campaigns.
• Publishing and Aggregation Platform Mashbot has an interface for publishing content to social
networks, as well as for aggregating social network data.
• Database Mashbot has an interface to a database which allows for the storage and retrieval of data
related to accounts and campaigns
Mashbot should be able to:
1. Schedule content for various services to be published concurrently
2. View and Compare historical metrics of campaigns
3. View/Create replies to content
4. Maintain users and approvers of content
5. Set up keyword alerts for “watched” services"
2004 - sprat.pdf;"Based on the utility of goals and scenarios, there is a need to develop a tool, which will assist analysts in the scenario and goal mining, reconciliation and management processes. The tool aims to maintain a goal and scenario repository for use in continuing analyses of policies and other documents from which goals and scenarios can be derived. All goals are fully traceable to the policies in which they are stated and are distinguished as either policy goals (strategic goals) or scenario goals (tactical goals) in each policy. This tool will provide strong management, which will offer flexible user defined conditions (like ID, keywords, taxonomy, subject, actor, and occurrences). The tool will also support automatic multi-user analysis results comparison. For example, each analyst can classify goals separately and the tool can automatically check the differences in their classification results for their resolution. The SPRAT will be comprised of 8 main modules:
- User Access Module – This module manages access levels and permissions for each class of user. The included access levels are: Administrator, Project Manager, Analysts, Guest
- Goal Specification and Management Module -This module supports goal management in the tool.
- Policy Management Module- This module supports policy management in the tool.
- Flesch Readability Index Module- This module supports requirements that calculate the Flesch Readability Index of policy documents.
- Scenario Specification and Management Module - This module supports scenario management in the tool.
- Requirements Specification Module- This module supports the requirements for a system.
- Legal Compliance
- Requirements-level Access Control Analysis Framework (RACAF) module- This section defines the functional requirements that support RACAF"
2009 - peazip.pdf;The tool's name is Peazip. The basic functions  that Peazip features are the: Creating compressed archives, updating compressed archives, extracting content of compressed archives, file and archive management tools(robust copy, split and join, fast or secure deletion, byte to byte comparison, calculation of a wide set of checksums and hashes over selected files), append timestamp to archive name(useful for archiving and backup purpose) and two factor authentication(password and keyfile) for the managed archives. All pre-mentioned functions’ parameters can be modified and adapted to user’s needs and preferences from a settings’ menu. 
2004 - phillips.doc;The MSN messenger xlet is a MHP version of the popular PC application. It is an application to demonstrate the possibilities of MHP and Platform-i. The Platform-i MSN messenger application is independent of other projects. The produced product will be an MHP MSN messenger xlet where there are only end-users. With the xlet the user shall be able to see online friends, chat with them and see which TV program they are watching. Unlike the PC variant, the xlet cannot transfer files and doesn’t have webcam support
2005 - nenios.html;The Child Care Management software is intended to provide a computer based system that will assist in managing a child care center. Many of the typical functions involved in operating a center will be automated through software to improve the operational workflow within a facility. For instance, activities like tracking child immunizations and maintaining classroom waiting lists will be performed by the computer system so that employees can spend more time caring for the children. In addition, tasks like processing invoices and printing customer reports will be available within the program to minimize the time that administrative staff must spend creating these documents. Before gaining access to the NCCM system an employee will be required to enter their user name and password. The NCCM system will store information in a database for future reference, teachers will have the ability to add or edit comments.Administrators can access a reporting feature that generates preformatted documents summarizing key customer information. In addition to printing these reports administrators are able to print invoices. Invoices will include a special notice if a child is due for a required immunization. Customers will be billed on the last day of every month with a discount applied to those accounts having multiple children enrolled in the Care Center. Daily reminders are a feature that all employees have access to. An employee can enter the date of an event as well as a message describing the event. On the day of the reminder a pop up message will be displayed when the employee logs onto the system. Acknowledgement of the reminder will permanently remove it from the database. Administrators are responsible for registering new customers.
2009 - warc III.pdf;The main goal of the WARC Tools project is to facilitate and promote the adoption of the WARC file format for storing web archives by the mainstream web development community by providing an open source software library, a set of command line tools, web server plug-ins and technical documentation for manipulation and management of web archive files or WARC files. This project has delivered a core software library called “libwarc” and a set of end user command line tools, extensions to existing tools, and simple web applications for accessing WARC content. In addition all the libraries have APIs and dynamic language bindings. The library and tools are scriptable (command lines in shell scripts, dynamic language bindings to the library), and programmable (dynamic language bindings, Java packages, and the C library itself). The last phase will build upon the original libwarc, extending the collection of WARC Tools and implement a full migration application. Phase III will include community participation in the speci!cation of the tools and applications, these will come from a number of International Internet Preservation Consortium (IIPC) member institutions, and similarly for testing. Phase III implementation will follow the original philosophy of providing powerful tools to enable crawl engineers, web archivists, researchers and other WARC users to easily manipulate and explore collections of web archive content without needing to write complex low-level code. 
2001 - esa.pdf;The ASPERA-3 instrument package (or ASPERA-3 experiment) will be flown on the Mars Express mission of the European Space Agency (ESA) and will be launched in June 2003 according to the current schedule. ASPERA-3 contains a number of different sensors that will measure the particles, neutral atoms, and fields in the near Martian environment. Southwest Research Institute is providing the data system to produce data products in a form suitable for analysis and archiving. These data products will be put into a form known as the Instrument Data File Set (IDFS). The ASPERA-3 Processing and Archiving Facility (APAF) is a ground data system responsible for processing all of the ASPERA-3 telemetry. The APAF data system acquires the telemetry data via NISN, processes the data into IDFS data sets, distributes the IDFS data sets to the ASPERA-3 team, provides web-based displays of the most current data for public view, stores the telemetry and IDFS data sets on a local SwRI archive, and submits the ASPERA-3 IDFS data sets to PDS for long-term archival. The first step in defining the IDFS data sets is to identify the physical instruments that make up the ASPERA-3 experiment and any ancillary data necessary for scientific analysis. There are six components of the ASPERA-3 package, plus the orbit and attitude data from the spacecraft: 1. Data Processing Unit (DPU) 2. Electron Spectrometer (ELS) 3. Ion Mass Analyzer (IMA) 4. Neutral Particle Detector (NPD) 5. Neutral Particle Imager (NPI) 6. Scanning Unit (SU) 7. Orbit/Attitude (OA) Each of the physical components will be divided into logical groups (called virtual instruments) in which each logical group will be formatted as an IDFS data set. Each of the seven components described above will have an associated Software Design Document (SDD) that will define and fully describe all of the data products contained within each individual virtual instrument.
2009 - model manager.pdf;"The Model Manager is a software tool that will allow the user to configure, schedule, run, monitor, and stop (and re-start /resume) model jobs. The primary goal of this project is to extend the current model back end system and to automate the setup, running and monitoring of model jobs. This will include a more automated node management system. The main functions of the system are:
1. Users of the system will be able to set up a new model or “postprocessing” job
2. Users of the system will be able to submit a 'by-hand' job or a job defined by a configuration file
3. Users of the system will be able to retrieve a previously saved job configuration
4. Users of the system will be able to change and save a job configuration
5. Users of the system will be able to start/restart/resume/stop a job
5. Users of the system will be able to monitor running jobs"
2004 - colorcast.pdf;"The product is a stand-alone web application with a theme mechanism to allow easy integration of the application into the ABC Paint website. The ColorKast solution is a server based application with a web-based client for consumer and enterprise access. In some respects, the application is the next generation of the old mechanical, hand-select, palette board system located in paint stores everywhere. Primarily, the application will include a old to new product-line “translator,” a graphical color chooser, a color search-engine, a user color palette, possibly, an easy to use color matching system, and an administrative interface. All of these will be defined and described later in this same document. The actual user interface will be described in a separate user interface specification whitepaper. All references to performance or specification apply to the application client. Specifications and performance estimates apply to the application server only if explicitly stated.
Functions are modularized sub-components of the client application. Each of the functions has a single purpose and can accomplish its mission without the other components. Together, the components function as a stand-alone application.
• Color Chooser (Pointing device driven color selection utility)
• Color number translator (old scheme -> new scheme)
• Find a particular number of colors near a given color
• Session persistent user color palette (colors picked, images uploaded)
• Color search engine (all collections, specific collection)
• Color matching (uploaded image)
• Administrative interface (update, add, delete colors, add users)"
2008 - caiso.pdf;Following the complete or major loss of system generation (blackout), it will be necessary to establish initial generation that can supply a source of electric power to other system generation and begin system restoration. These initiating generators are referred to as system Black Start generators. They must be able to self-start without any source of off-site electric power and maintain adequate voltage and frequency while energizing isolated transmission facilities and auxiliary loads of other generators. Generators that can safely reject load down to their auxiliary load are another form of Black Start generator that can aid system restoration, but are not addressed with this Black Start Capability Plan (BCP). From a planning perspective, a system Black Start Capability Plan (BCP) is necessary to ensure that the quantity and location of system Black Start generators are sufficient and that they can perform their expected functions as specified in overall coordinated WECC BCP. The CAISO may from time to time test Unit(s) designated to provide Black Start service (through an RMR or Interim Black Start Contract) by requiring the Unit to deliver Black Start service pursuant to a Test Dispatch Notice provided to Owner’s Scheduling Coordinator. The Black Start Test shall be performed in accordance with the Ancillary Services Requirements Protocol in the CAISO Tariff. The CAISO shall not request a Black Start Test for a hydroelectric Unit during periods of constrained water availability.
2004 - ijis.doc;The Integrated Justice Information System (IJIS) is an initiative being undertaken by Tarrant County, Texas. The vision for IJIS is to define and develop enhanced business processes and supporting technology solutions that result in a more effective and efficient administration of justice in Tarrant County. When complete, IJIS will facilitate rapid sharing of information across the Criminal Justice Community while providing each stakeholder with advanced justice management capabilities. The system must submit requests for appointed counsel, process requests for appointed counsel, manage notifications, manage reporting, manage notice of case filing decisions, manage defendant contact, manage attorney list and manage defense attorney compensation
2009 - video search.pdf;"The system will be a search engine for finding the location of torrents and streaming sites for videos on the internet. The user can specify which of the 2 or both to look for. The results will be divided into the types that were specified using different tabs, and then the results will be orderable by different categories, such as name, size, site, etc. The user will have the option to filter out videos containing certain content depending on age restrictions, for example adult content. In addition the user will have the option to filter out or only search certain websites; for example a user may only want to look at videos on YouTube. They will have the facility for users to store their favorite videos, so that they can come back to the video at another time. There will be two levels of user for our system. The first will be the general user that will be using our software to find their videos. They will only see the front end of the system. The second level will be the system developers. They will be able to edit which sites the system will search, depending on whether they think the site is safe, compatible with our software, the speed at which the site can be searched, and how useful the site is to us, i.e. how many results have come back from that site. "
2006 - stewards.pdf;"This product is a new, centralized data system. Source data for this system are the long-term  Agricultural Research Service (ARS) watersheds, with those participating in the Conservation Effects Assessment Project (CEAP) project expected to participate in this data system first. The data system consists two main parts -- a central database management system for the uploading, storage, and management of data, and a client application to allow users access and interact with the data. Diverse end-users can access, search, analyze, visualize, download, and report various types of integrated watershed data contributed from the multiple locations. Types of data will include biophysical data (i.e., point-based in time and/or space, spatially variable data, time series), data about land use, management, and conservation practices; and economic data."
2002 - evla back.pdf;"The Correlator Backend System lies between the Correlator and the End-to-End Systems. It is the primary component of the real-time astronomical data processing capability (the processing pipeline) of the EVLA. Its primary responsibility is to perform basic data assembly, formatting and processing services and to support the desire for real-time inspection of the astronomical data stream. The major functions the Correlator Backend System must perform are as follows:  Receive data from the Correlator in real-time.  Assemble time-series from the Correlator lag output.  Perform Fourier Transforms of the assembled time series.  Perform a limited number of additional processes upon user request.  Deliver suitably formatted results to the End-to-End System.Correlator lag data will be received directly from the Correlator Baseline Boards in the form of Lag Frames. The lag frames contain correlation lag values and all auxiliary parameters needed to assemble the lags into complete lag sets (properly ordered time series). It is currently assumed that all observational modes yielding correlator results that are transmitted to the Backend will be in the form of lag frames.
Additional auxiliary data and meta-data needed for processing prior to output to the e2e System will arrive via the Monitor and Control System, whether produced by the Correlator or some other part of the EVLA System. The BE will receive and act upon status requests and control commands originating in or via the
M&C System.
The Correlator lag frames will be assembled into time series, normalized, and when necessary time stamp adjusted. The time series will also be Fourier Transformed and other user selectable time and/or frequency domain processes will be applied. Prior to output, the end results will be formatted to meet the internal needs of the e2e.
Formatted spectra will be transferred to the End-to-End System. All pertinent meta-data will be contained in the formatted output. The fundamental unit of output is the minimum sub-band crosspower spectrum produced by the Correlator. (No “stitching” operations that combine spectra from different sub-bands will be performed.) The BE will produce a variety of error, warning, status and other reports and messages that will be transferred to the M&C for final disposition. EVLA Operations System SRS 5. The Correlator Backend System will conduct a number of self-monitoring activities on application and system software as well as hardware systems to detect system failure and out of spec conditions. The ability to attempt recovery from failure and out of spec performance conditions will be built
into the system. The system will provide control and auxiliary parameters to input, output, processing, monitor, recovery, and other functions and receive status and performance data from them. It will also communicate with the external Monitor and Control System. "
2002 - evla corr.pdf;"The Correlator Monitor & Control System (CMCS) provides the physical link between the WIDAR Correlator hardware and the EVLA monitor & control system. It is the primary interface by which the correlator is configured, operated, and serviced. The primary functions of the Correlator Monitor & Control System are as follows: · Receive configuration information from the EVLA M&C system and translate this info into a physical correlator hardware configuration. · Process and transfer dynamic control data (models, filter parameters, etc), and monitor data (auto correlation products, state counts, etc.) · Monitor Correlator and correlator subsystem health and take corrective action autonomously (where possible) to recover from hardware and computing system faults. · Perform limited amounts of real-time data processing and probing such as providing tools to collect and display auto correlation products. · Allow for easy system access to aid testing and debugging. The EVLA Correlator Monitor and Control System is responsible for correlator configuration, real time monitor/control, and hardware testing/servicing. The CMCS exists as an integrated part of the overall EVLA Monitor and Control Structure. The CMCS will provide a level of abstraction to modularize the correlator system within the EVLA environment. The “gateway” to the correlator will be through the Virtual Correlator Interface (VCI) which will exist as a software entity on the MCCC.
The CMCS will be designed and implemented as a Master/Slave network with one computer system coordinating the activities of a number of “intelligent” hardware control processors. The Master is expected to handle the bulk of the monitor/control interface with the outside world whereas the slaves will be only concerned with the correlator hardware systems under their direct control. This topology will place the real-time computing requirements in the slave layer and the quasi real-time, network-chaotic loads into the master layer. One of the primary benefits of this structure is isolation (ease of serviceability, programmability) of the correlator hardware from the EVLA M&C environment. The system is expected to be redundant in critical areas and highly modular."
2009 - email.pdf;Statewide e-mail system.--A state e-mail system that includes the service delivery and support for a statewide e-mail, messaging, and calendaring service is established as an enterprise information technology service as defined in s. 282.0041. The service shall be designed to meet the needs of all executive branch agencies and reduce the current cost of operation and support.
2009 - gaia.pdf;"GOG is a tool to directly get Catalogue, Main Database (MDB) data and final (in the sense of statistically equivalent to the final mission data) data without the use GASS telemetry, GIBIS or the main ESAC database The Gaia Object Generator (GOG) is expected to simulate catalog data, auxiliary data and intermediate main database data (including mission final data) for all the Gaia instruments. It will use error models to provide rapid simulations of large amount of data.  This ’Software Product’ is composed of several ’Modules’:
- The initialisation modules is in charge of loading and storing the read configuration in a proper way. The module has to offer a common interface to get values from the configuration in an easy manner.
- The epoch parameters module is in charge of all the epoch parameters settings and calculations of the GOG simulation.
- The combined parameters module is in charge of all the combined parameters settings and calculations of the GOG simulation
- The spectrum module is in charge of all the spectrum settings and calculations of the GOG simulation. 
- The output module comunicates GOG flow execution with the filesystem. When the flow request a file it obtains it from the system and also it writes the files requested as GOG outputs"
2007 - mdot.pdf;"A strategy is laid out in the Michigan Department of Transportation VehicleInfrastructure Integration Strategic and Business Plan that focuses on partnering, developing, and deploying a VII (Vehicle Infrastructure Integration) infrastructure and test beds; increasing safety and mobility; improving asset management; developing outreach programs to better expose others to VII in Michigan; justifying the need for VII; and determining creative investment funding venues for VII activities. DUAP (Data Use Analysis and Processing) is a research program to determine how new VII data impacts safety, traffic operations and management, asset management, winter operations, and transportation planning. The program is focused on demonstration and assessment of data transformation and management, and DUAP system development is a means to that end. From a systems engineering functional viewpoint, the DUAP system has four high-level capabilities:
• Collecting data
• Consolidating the collected information
• Converting data into information needed by transportation agencies
• Communicating the unified information to various agencies and the public 
The input services of the DUAP system will: receive probe data from individual vehicles; receive traffic information from Advanced Traffic Management Systems (ATMS) throughout the state; receive weather information from several sources; and receive traveler information from Advanced Traveler Information Systems (ATIS) throughout the state, as well as other governmental and commercial sources. 
The dynamic data services are a caching service intended to store DUAP data for fast access over a relatively short duration. 
Persistent data services provide longer-term storage within DUAP of both data collected by input services and metadata needed by DUAP services to sustain their operations.
The purpose of the DUAP system’s computational services is to apply logical algorithms to incoming vehicle and traffic observations in order to transform those observations into data that is directly applicable to transportation management and operations processes.
Output services subscribe to analyzed data and format it for use by other services both within the DUAP system and external to it. 
Presentation Services support human interpretation of DUAP data. 
Administrative services will exist within the DUAP system to configure other services. Essentially, administrative services fulfill the role of “meta-services.” These services will be used to organize the sequence of execution for any of the other services, view logging information, and to change the operating modes of the system. "
2008 - keepass.pdf;KeePass is a password manager. KeePass consists of a database which contains data for one or more users. Each user’s data are divided into groups and subgroups so that they are organized in a form that serves right the user. Every user has a unique Master Key which can be simple or composite and its combination opens uniquely the database. If lost there is no recovery. Groups and subgroups contain entries with usernames, passwords URLs etc that can be sent or copied to websites, application and accounts. There is also the ability for a onetime key creation to be used once in a transaction without the risk of reused by others for any reason.
2001 - libra.doc;"Libra forms part of a larger system comprising the Sun Grid Engine cluster management system that runs on a Linux-based cluster. SGE is responsible for receiving the jobs submitted by the user and delegating them to Libra for scheduling and placing on appropriate workstations or execution hosts. Libra communicates its decision regarding workstation allocation to the resource manager, which then dispatches the job to the chosen workstation. Once assignment to a workstation has occurred, Libra is responsible for implementing the scheduling policy on the jobs executing at the workstations. the Libra scheduler will be QoS driven: it will aim to optimize resource utilization within user-imposed constraints: thus, user satisfaction is the primary concern, as opposed to maximizing CPU utilization. Thus, the two job parameters most relevant to the scheduling decisions will be:
• Budget allocated by the user to the process
• Deadline
"
2001 - space fractions.pdf;The Space Fractions project is a learning tool created to help improve fraction-solving skills for sixth-grade students. The product will be a web-based, interactive game. At the end of the game, students will be given feedback based on their game scores. We are also providing an umbrella for the past games created. The umbrella will be a web-based menu system allowing the user to choose between the games.
0000 - inventory.pdf;"IUFA purpose is to integrate 3 faculties data bases providing Web interface that allows user to access and manage the integrated inventory. The IUFA guarantee a secure access to the data from outside university at any time during working hours .Assets in the inventory are classified in 3 types: Rooms and space; Software licences and All other assets
 The IUFA application give the unauthorised user the possibility to use a web based interface that will available to use any time IUfA involve to the following operations: - Transferring assets - Editing assets - Modifying assets - Adding inventory assets  - Creating request to borrow an asset or a reserve a space - Retuning assets - Creating a new space - Approving requests - Authentication - Search - Changing permission - Output reports. "
2007 - puget sound.pdf;"The University of Puget Sound is currently seeking a new courseware system and is investigating Moodle as an option. Moodle is courseware system that managers courses, assignments, wiki pages, forums, etc. Our goal is to refine parts of Moodle to provide functionality that improves the overall learning experience of students at the University and helps professors to make students aware of new ways of presenting material.
Students are the primary consumers of a courseware system. They are accessing information posted by professors, uploading assignments and project files, and discussing concepts.
Professors are the primary content administrators of a courseware system. They are uploading files, links, and multimedia, and grading assignments in addition to creating new places for students to discuss and collaborate.
System Administrators are primarily responsible for maintaining the courseware system. They contribute minimally to the courses themselves, but spend more time modifying the system’s configuration and making appropriate updates
"
2005 - grid 3D.pdf;"The need for a method of visualisation of biological data has been identified. Currently, there are many groups offering many different tools for visualising data. These visualisation tools provide a range from tabular to three-dimensional graphical views. However, a need has been identified for a tool that can display data in a three dimensional environment, which allows the user to investigate the data and easily see various attributes of the data at a glance. The main actors in the systems are the identifier, the investigator and the demonstrator. 
The initiation phase of this Grid 3D application consist of these actors getting biological data. The identifier supplies data to the application, and the application returns point of view / info. The investigator also supplies data to the application, and the application returns information. The app supplies data to the demonstrator and the demonstrator returns 3D view.
When 3D grid application is running: the demonstrator, investigator and identifier command the app to rotate the grid, zoom the grid, move the grid, select point(s) or retrieve point info. The application must return desired Graphical Representation."
0000 - gamma j.pdf;"GAMMA-J’s Web Store is designed to allow new online store owners a quick and easy means to setup and perform sales and other core business over the internet. This Web Store will:
• Manage customer accounts
• Manage an online store inventory
• Manage a customer’s “Shopping Cart”
• Confirm Orders
• Have an unambiguous interface to assist in browsing the categories and products
• Use Secure Socket Layer (SSL) for security
• Have an availability of 99.999%
• Allow an optional mirror site for reliability and backups
• Feature interface for future software enhancement via “Plug-ins”
The initial inventory will be 100 items. Expandable with unique codes, the owners can purchase to expand the inventory. The minimum total inventory will be 20,000 items. Since this will be a “Plug and Play device”, no software installation will be necessary. This software will contain all of the basic needs to manage an online store. Advanced needs can be added in the future via “plug-ins.” "
2005 - pontis.pdf;"Pontis is a software application developed to assist in managing highway bridges and other structures. The system is designed to support the bridge inspection process, recommend a bridge preservation policy, predict future bridge conditions, and recommend projects to perform on one or more bridges to derive the most agency and user benefit from a specified budget. Pontis 5.0 will provide licensing agencies with an up-to-date tool for bridge management, including data management, condition assessment, model development, needs analysis, reporting, and interaction with other agency systems. Pontis 5.0 will be the next generation of the Pontis product, currently deployed in more than 45 agencies in the U.S. and abroad. This product is intended to replace the existing Pontis 4.x product line with a next-generation software application, utilizing state-of-the-art software development technology.The baseline capabilities will be extended to provide licensees the ability to access selected modules from a web browser as well as a dedicated client application, depending on the particular BMS (Bridge Management System) activity. A web version of Pontis will offer easier application setup, administration, and implementation, and will provide a straightforward migration path for existing Pontis 4.x users. Pontis 5.0 will support a range of new functionality, including: import and export of data in eXstensible Markup Language (XML) based on the TransXML schema being developed through National Cooperative Highway Research Program (NCHRP) Project 20-64, XML Schemas for Exchange of Transportation Data (TransXML); improved approaches to modeling bridge needs through incorporation of research results from NCHRP 12-67, Multiple-Objective Optimization for Bridge Management Systems; improved user interfaces for bridge-level analysis and project planning; and support for multiple asset types. Further, Pontis 5.0 will provide seamless support to its licensees for potential changes in the National Bridge Inventory (NBI) coding standards.
The development of Pontis 5.0 is driven in part by new functional requirements as well as by dramatic technology changes in the software development arena that have overtaken the existing client/server application, particularly in the web
application development domain.
The goals for Pontis 5.0 are to provide the AASHTO (American Association of State Highway and Transportation Officials) member agencies and licensees with:
A readily-accessible, robust repository for bridge information, including data inventory, condition, needs, project plans, and accomplishments;
Technically correct capabilities to perform bridge management tasks of all types;
A technologically up-to-date development foundation;
Streamlined, simpler application and deployment mechanisms;
A flexible, customizable application which users can extend to solve agencyspecific bridge management tasks; and
Preservation of significant agency investments in BMS generally and Pontis specifically, including expenditures of time, money, training and other agency resources."
2008 - virtual ed.doc;"Virtual-EDU consists of an online website that allows users to create a classroom like environment with the features that it contains. Once registered to the system, a user can create a profile sharing his or her information with the rest of the enrolled users. Users will be able to find commonalities with each other through the user profile. Virtual-EDU also gives users the ability to store data and/or important materials in a secure network location for future retrieval or present usage. This particular data as well as other files may be shared or worked on using Virtual-EDU extensive tools for file sharing and document collaboration. Users can work together on a single document in real time or send their work to other users via secure file sharing methods and protocols. If further communication is need between users, Virtual-EDU has features such as instant messaging, where users can hold single or group conversations via a secure real-time communication based on typed text. However, if more efficient means of communication are need, users have the ability to hold single or group video/audio conferences, whereby the users will be able to see other users streamed live in real-time.
Virtual-EDU features: instant messaging, video and audio streaming, file sharing, document collaboration, hosting space and user profiles."
1998 - themas.pdf;"The THEMAS system is a system that operates independent of any other system, or any components of the heating and cooling system to which it is attached. The THEMAS system, however, is composed mainly of a hardware and software portion. The THEMAS system is divided into four major sections: Monitor Temperature, Determine Utilization, Initialize System, and System Reports. All four sections have an associated software configuration item; all except the System Reports have an
associated hardware configuration item.
The monitor temperature function receives the valid temperature and system parameters. The function then goes through the process of determining temperature status. After this process is done, either temperature limit is exceeded or the temperature change is requested. If the temperature change is requested, then the determine heating/cooling mode process is activated and makes a heating/cooling request. Some other processes that help the monitor temperature function are: validate temperature, change thermostat setting, generate alarm, and system initialization.
The determine utilization function receives the heating/cooling request and utilization parameters. The function then processes the status of all heating/cooling units and sends out either unit unavailable or heating/cooling unit needed. The function generates either a unit unavailable event which goes into the System Reports function or it generates a heating/cooling signal to turn on/off the units. The Monitor Temperature and Initialize System functions help the determine utilization to do its processes.
The initialize system function receives the initialization data for the THEMAS system. The processes that are associated with it are: load heating/cooling unit definitions, turn off all heating/cooling units, load th ermostat definitions, load utilization parameters, set trigger values, set overtemperature values, and establish valid temperature range. The outgoing information that starts the entire THEMAS system is: clear all heating/cooling signals, send thermostat definitions, send utilization parameters, send trigger values, send overtemperature values, and send valid temperature range.
The system reports function receives event data from the THEMAS system. This function is a database that stores all the events in the THEMAS system. This function is mainly for the use of the supervisor of the THEMAS system to maintain an efficient heating and cooling system. The only process that interacts with the system reports function is the generate event data process."
2009 - library.pdf;"This is  the System Administration Module of an Integrated Library System (ILS). The System Administration Module facilitates the management of every aspect of the Integrated Library System. Specifically, the System Administration Module support the following activities, among others:
• Configuring the ILS to enable and support features and processes required for management of the Library branches, patrons, collections, and circulation transactions.
• Monitoring, troubleshooting, and controlling server performance.
• Monitoring, troubleshooting, and controlling database and application performance.
• Monitoring, troubleshooting, and controlling services, ports, and application programming interfaces.
• Managing user and group accounts and privileges.
• Managing server and client software installation, upgrades, and updates.
• Backing up databases, configuration files, log files, etc. "
2001 - ctc network.pdf;"This system is for the Dallas/Ft. Worth (DFW) Regional “Center-toCenter (C2C) Communications Network” that is based on a Texas Department of Transportation
(TxDOT) C2C project. The TxDOT C2c project initially connected the DFW TxDOT Traffic Management Centers (TMCs). This C2C infrastructure implements a repository for traffic data and provides a mechanism to exchange device control information between TMCs. The C2C infrastructure must interconnect several dissimilar traffic management systems. In order to create the C2C infrastructure, interfaces to the existing systems will be created. The data from these interfaces will communicate with the existing system in a “system specific” format. The data being deposited into the C2C infrastructure will be converted to a standard format (based on the ITS standards). The C2C infrastructure is being created using a series of building blocks. These building blocks allow the software to be utilized in a number of configurations (by simply altering the configuration parameters of the software). The C2C project has the following goals:
· To provide a common repository for traffic information for the DFW Metroplex.
· To provide a World Wide Web based graphical map to display traffic conditions in the DFW Metroplex.
· To provide a Microsoft Windows application that will allow agencies without a formal Traffic Management Center (TMC) to participate in the C2C infrastructure and
information sharing.
· To provide a system which supports ITS center-to-center communications for command/control/status of various ITS field devices including: Dynamic Message
Signs, Lane Control Signals and Closed Circuit Television Cameras (CCTVs), Ramp Meters, and Highway Advisory Radios (HARs).
· To utilize National ITS standards to implement the project.
· To provide a software system that is extensible all local or regional partners. This would allow a “local” common repository to be created by “linking” individual
partners, a “regional” common repository to be created by “linking” local common repositories and a “statewide” common repository to be created by “linking” regional common repositories."
