{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown -U\n!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-08-28T15:08:03.512978Z","iopub.execute_input":"2024-08-28T15:08:03.513398Z","iopub.status.idle":"2024-08-28T15:08:30.461756Z","shell.execute_reply.started":"2024-08-28T15:08:03.513361Z","shell.execute_reply":"2024-08-28T15:08:30.460539Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.20.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"]=\"true\"","metadata":{"execution":{"iopub.status.busy":"2024-08-28T15:10:06.142891Z","iopub.execute_input":"2024-08-28T15:10:06.143310Z","iopub.status.idle":"2024-08-28T15:10:06.148704Z","shell.execute_reply.started":"2024-08-28T15:10:06.143275Z","shell.execute_reply":"2024-08-28T15:10:06.147565Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mkdir -p results_docs_bert","metadata":{"execution":{"iopub.status.busy":"2024-08-28T15:10:08.940792Z","iopub.execute_input":"2024-08-28T15:10:08.941148Z","iopub.status.idle":"2024-08-28T15:10:09.958995Z","shell.execute_reply.started":"2024-08-28T15:10:08.941122Z","shell.execute_reply":"2024-08-28T15:10:09.957785Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# cargar dataset de google drive\n!gdown '1pl9hGX3_4lMJvl4thbwkEXRCTi_dH1au'","metadata":{"execution":{"iopub.status.busy":"2024-08-28T15:10:11.730840Z","iopub.execute_input":"2024-08-28T15:10:11.731251Z","iopub.status.idle":"2024-08-28T15:10:16.907109Z","shell.execute_reply.started":"2024-08-28T15:10:11.731208Z","shell.execute_reply":"2024-08-28T15:10:16.906023Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1pl9hGX3_4lMJvl4thbwkEXRCTi_dH1au\nTo: /kaggle/working/ReWoRC_Dataset_req.csv\n100%|█████████████████████████████████████████| 437k/437k [00:00<00:00, 104MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Aqui empiezo el código igual al de colab","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-28T15:10:25.247461Z","iopub.execute_input":"2024-08-28T15:10:25.248644Z","iopub.status.idle":"2024-08-28T15:10:26.903861Z","shell.execute_reply.started":"2024-08-28T15:10:25.248602Z","shell.execute_reply":"2024-08-28T15:10:26.902753Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"FILE_REQ='/kaggle/working/ReWoRC_Dataset_req.csv'\ndata_req = load_dataset('csv', data_files=FILE_REQ, sep=';')\nprint(data_req['train']['NFR'][21])\n\ndef create_labels(row):\n  return {'labels': 'F' if row['NFR'] == 'Funcional' else 'NF', 'id_doc':row['Documento']}\n\ndata_req = data_req.map(create_labels)\ndata_req = data_req.class_encode_column('labels')\ndata_req = data_req.class_encode_column('id_doc')\nprint(set(data_req['train']['labels']))\ndata_req = data_req['train']\ndata_req.features","metadata":{"execution":{"iopub.status.busy":"2024-08-28T15:10:26.905801Z","iopub.execute_input":"2024-08-28T15:10:26.906385Z","iopub.status.idle":"2024-08-28T15:10:27.873432Z","shell.execute_reply.started":"2024-08-28T15:10:26.906348Z","shell.execute_reply":"2024-08-28T15:10:27.872430Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0adc0fe4dfc84b919040ced146a236de"}},"metadata":{}},{"name":"stdout","text":"No funcional\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60d446d136df4b69a5ab34256689787e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60701e55cd27403f8b1a644caa56010d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4773550de12a4767908415bcd3678107"}},"metadata":{}},{"name":"stdout","text":"{0, 1}\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'Num': Value(dtype='int64', id=None),\n 'Referencia': Value(dtype='string', id=None),\n 'Requisito': Value(dtype='string', id=None),\n 'Documento': Value(dtype='string', id=None),\n 'NFR': Value(dtype='string', id=None),\n 'labels': ClassLabel(names=['F', 'NF'], id=None),\n 'id_doc': ClassLabel(names=['0000 - gamma j.pdf', '0000 - inventory.pdf', '1998 - themas.pdf', '1999 - multi-mahjong.html', '2001 - beyond.pdf', '2001 - ctc network.pdf', '2001 - esa.pdf', '2001 - hats.pdf', '2001 - libra.doc', '2001 - space fractions.pdf', '2002 - evla back.pdf', '2002 - evla corr.pdf', '2003 - agentmom.pdf', '2003 - pnnl.pdf', '2003 - qheadache.pdf', '2003 - tachonet.pdf', '2004 - colorcast.pdf', '2004 - ijis.doc', '2004 - phillips.doc', '2004 - rlcs.pdf', '2004 - sprat.pdf', '2005 - clarus low.pdf', '2005 - grid 3D.pdf', '2005 - microcare.pdf', '2005 - nenios.html', '2005 - phin.pdf', '2005 - pontis.pdf', '2005 - triangle.pdf', '2005 - znix.pdf', '2006 - stewards.pdf', '2007 - e-store.pdf', '2007 - eirene fun 7.pdf', '2007 - mdot.pdf', '2007 - puget sound.pdf', '2007 - water use.pdf', '2008 - caiso.pdf', '2008 - keepass.pdf', '2008 - virtual ed.doc', '2008 - vub.pdf', '2009 - email.pdf', '2009 - gaia.pdf', '2009 - inventory 2.0.pdf', '2009 - library.pdf', '2009 - model manager.pdf', '2009 - peazip.pdf', '2009 - video search.pdf', '2009 - warc III.pdf', '2010 - digital home 1.3.pdf', '2010 - mashboot.pdf', '2010 - split merge.pdf'], id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n#BERT: model_name = 'google-bert/bert-base-cased'\n#DEBERTA: model_name = 'microsoft/deberta-v3-base'\n#ROBERTA: model_name = 'FacebookAI/roberta-base'\nmodel_name = 'google-bert/bert-base-cased' # modificar con el modelo que queramos cada vez","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:15.170446Z","iopub.execute_input":"2024-08-04T09:59:15.170864Z","iopub.status.idle":"2024-08-04T09:59:15.175274Z","shell.execute_reply.started":"2024-08-04T09:59:15.170829Z","shell.execute_reply":"2024-08-04T09:59:15.174448Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:15.176456Z","iopub.execute_input":"2024-08-04T09:59:15.176726Z","iopub.status.idle":"2024-08-04T09:59:17.522386Z","shell.execute_reply.started":"2024-08-04T09:59:15.176699Z","shell.execute_reply":"2024-08-04T09:59:17.521517Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"133ea32332f44b64970cecc42ab207a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d96623b1b948759dda9e54ae873b2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1929e13204154a1598f617b4343dad7b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def encode_text(row, tokenizer):\n  row_encode = tokenizer(row['Requisito'], truncation=True)\n  return row_encode\n\n\nencode_data = data_req.map(encode_text, fn_kwargs={'tokenizer':tokenizer})\nencode_data\n\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\nfolds = KFold(n_splits=10, shuffle=True)\n\nsplits = folds.split(np.zeros(50))\ntest_sets = []\ntrain_val_sets = []\ni=1\nfor train_val_idxs, test_idxs in splits:\n  print (i)\n  print(test_idxs)\n  print('*******')\n  data_test = encode_data.filter(lambda r : r['id_doc'] in test_idxs)\n  data_train = encode_data.filter(lambda r : r['id_doc'] in train_val_idxs)\n  data_train_val = data_train.train_test_split(train_size=0.9, stratify_by_column='labels')\n  print(data_test)\n  print(data_train)\n  print(data_test.num_rows + data_train.num_rows)\n  print(encode_data.num_rows == (data_test.num_rows + data_train.num_rows))\n  print(\"***\")\n\n\n  test_sets.append(data_test)\n  train_val_sets.append(data_train_val)\n  i = i + 1\n\nprint(test_sets[0])\nprint(train_val_sets[0]['test'])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:17.523673Z","iopub.execute_input":"2024-08-04T09:59:17.523939Z","iopub.status.idle":"2024-08-04T09:59:23.346376Z","shell.execute_reply.started":"2024-08-04T09:59:17.523915Z","shell.execute_reply":"2024-08-04T09:59:23.345439Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2929cfb346a94b7c87acb2ddbee9e076"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"1\n[13 17 30 39 45]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecde073bcc3744b796e8ee23e317e227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d7e0e4edff4e079868e75182c932a2"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 249\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2142\n})\n2391\nTrue\n***\n2\n[19 25 26 32 48]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6012b2f5257744fa83a2b5a9e461d173"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7588213205243b2b131977a7f5410ab"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 446\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 1945\n})\n2391\nTrue\n***\n3\n[ 3  4  8 12 37]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f960dfbb1de4644af3969a0542a3617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a80ea67144924b868494d33705ab2ce5"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 196\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2195\n})\n2391\nTrue\n***\n4\n[ 6 15 41 46 47]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b3ffd77e5c48ffb922db1c0a6494a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b005ad25c8d49e4bf46780d6211abb5"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 183\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2208\n})\n2391\nTrue\n***\n5\n[ 9 16 24 31 34]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888354667dab493e88e97fb81a794a9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"838927d6f066410b81125da53231afb9"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 244\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2147\n})\n2391\nTrue\n***\n6\n[ 0  5 27 33 44]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b4a58a427f042fca725667b337f63c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"531f113809274e40ad5bca2f86234be6"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 189\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2202\n})\n2391\nTrue\n***\n7\n[ 1 11 21 29 36]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b85c767010645748776f4f62a2dbc9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebbddcad28174f76823d4b8781e8458b"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 244\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2147\n})\n2391\nTrue\n***\n8\n[ 2 23 35 40 43]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a517417654104fe6ae3aa87b969a1c01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d69e2357433d480b9062cfcdc12f18eb"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 169\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2222\n})\n2391\nTrue\n***\n9\n[10 18 20 22 49]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b848f16ae15491cac80b428e1aed7f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38badccc9adc45c7b79b157306c24b77"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 183\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2208\n})\n2391\nTrue\n***\n10\n[ 7 14 28 38 42]\n*******\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aa4225cd734401eb2d7678b38d571de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2391 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1c3bc402ac64fc1bcdcae6861edcb46"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 288\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2103\n})\n2391\nTrue\n***\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 249\n})\nDataset({\n    features: ['Num', 'Referencia', 'Requisito', 'Documento', 'NFR', 'labels', 'id_doc', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 215\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:23.350011Z","iopub.execute_input":"2024-08-04T09:59:23.350588Z","iopub.status.idle":"2024-08-04T09:59:25.468333Z","shell.execute_reply.started":"2024-08-04T09:59:23.350559Z","shell.execute_reply":"2024-08-04T09:59:25.467546Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e256ed11f92439eadbb61225d0b49d1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:25.469731Z","iopub.execute_input":"2024-08-04T09:59:25.470111Z","iopub.status.idle":"2024-08-04T09:59:25.474672Z","shell.execute_reply.started":"2024-08-04T09:59:25.470074Z","shell.execute_reply":"2024-08-04T09:59:25.473812Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis = 1)\n    return metric.compute(predictions=predictions, references=labels)\n\n# load metric\nmetric_name = 'f1'\nmetric = evaluate.load(metric_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:25.475963Z","iopub.execute_input":"2024-08-04T09:59:25.476542Z","iopub.status.idle":"2024-08-04T09:59:25.944161Z","shell.execute_reply.started":"2024-08-04T09:59:25.476508Z","shell.execute_reply":"2024-08-04T09:59:25.943367Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import glob\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import classification_report\n\nlr_values =[2e-5, 5e-5]\n\nfor j in range(len(train_val_sets)):\n    best_lr = -1\n    best_f1 = -1\n\n    # para escribir los resultados\n    with open(f'results_docs_bert/res_docs_bert_{j}.txt', 'w') as f:\n    # NOTA: si no va, deshacer el tab extra del siguiente bucle for\n      for i, lr in enumerate(lr_values):\n        print(\"================================================\")\n        print(\"j = \" + str(j) + \" // lr = \" + str(lr))\n        print(\"================================================\")\n      # argumentos para el entrenamiento\n        training_args = TrainingArguments(\n            #output_dir=\"my_checkpoint\"+str(j),\n            output_dir=f\"my_checkpoint_{i}\",\n            overwrite_output_dir = True,\n            num_train_epochs=10,\n            #para probar tanto promise como nuestro coger 10 epochs\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            save_total_limit = 1,\n            load_best_model_at_end=True,\n            logging_strategy='epoch',\n            optim=\"adamw_torch\",\n            per_device_train_batch_size=32,\n            #lo dejaremos en 32\n            #per_device_eval_batch_size=32,\n            learning_rate=lr,\n            #probar tanto 2e-5 como 5e-5\n            weight_decay=0.01,\n        )\n\n        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n        # declarar el \"entrenador\"\n        trainer = Trainer(\n            model=model,\n            args=training_args,\n            train_dataset=train_val_sets[j]['train'],\n            eval_dataset=train_val_sets[j]['test'],\n            tokenizer=tokenizer,\n            compute_metrics=compute_metrics\n        )\n\n        # realizar el entrenamiento\n        trainer.train()\n\n        out_pred = trainer.predict(data_train_val['test'])\n        if out_pred.metrics['test_f1'] > best_f1:\n          best_f1 = out_pred.metrics['test_f1']\n          best_lr = i\n      # cargar el mejor modelo y resultados para test\n      best_dir = glob.glob(f\"my_checkpoint_{best_lr}/checkpoint*\")\n      print(best_dir)\n      model_best = AutoModelForSequenceClassification.from_pretrained(best_dir[0])\n      trainer_best = Trainer(\n            model=model_best,\n            args=None,\n            train_dataset=None,\n            eval_dataset=None,\n            tokenizer=tokenizer,\n            compute_metrics=compute_metrics\n        )\n\n      test_data = test_sets[j]\n      outputs_pred = trainer_best.predict(test_dataset=test_data)\n\n      # model predictions\n      predictions = np.argmax(outputs_pred.predictions, axis=1)\n\n      #d_res = classification_report(test_data['labels'], predictions, digits=3, return_dict = True)\n      d_res = classification_report(test_data['labels'], predictions, digits=3, output_dict=True)\n      print(d_res)\n      f.write(\"================== Best lr ================\\n\")\n      f.write(str(best_lr))\n      f.write(\"\\n\")\n      f.write( \"================== Resultados ================\\n\")\n      f.write(str(d_res))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:59:25.945275Z","iopub.execute_input":"2024-08-04T09:59:25.945547Z","iopub.status.idle":"2024-08-04T11:41:25.235769Z","shell.execute_reply.started":"2024-08-04T09:59:25.945522Z","shell.execute_reply":"2024-08-04T11:41:25.234710Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 0 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [610/610 05:05, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.417800</td>\n      <td>0.234118</td>\n      <td>0.776119</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.197700</td>\n      <td>0.130564</td>\n      <td>0.862069</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.133600</td>\n      <td>0.132788</td>\n      <td>0.830769</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.098000</td>\n      <td>0.179714</td>\n      <td>0.763636</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.051100</td>\n      <td>0.186520</td>\n      <td>0.825397</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.030300</td>\n      <td>0.221070</td>\n      <td>0.805970</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.018400</td>\n      <td>0.224874</td>\n      <td>0.843750</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.009000</td>\n      <td>0.219526</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.009600</td>\n      <td>0.255440</td>\n      <td>0.843750</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.008200</td>\n      <td>0.244914</td>\n      <td>0.857143</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 0 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [610/610 04:56, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.354400</td>\n      <td>0.333698</td>\n      <td>0.582524</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.196500</td>\n      <td>0.157327</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.104300</td>\n      <td>0.148793</td>\n      <td>0.847458</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.060600</td>\n      <td>0.174891</td>\n      <td>0.847458</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.027600</td>\n      <td>0.184049</td>\n      <td>0.847458</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.016500</td>\n      <td>0.198875</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.011400</td>\n      <td>0.212550</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.009300</td>\n      <td>0.252703</td>\n      <td>0.843750</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.005400</td>\n      <td>0.247711</td>\n      <td>0.838710</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.003100</td>\n      <td>0.252816</td>\n      <td>0.838710</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_1/checkpoint-183']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.875, 'recall': 0.9792746113989638, 'f1-score': 0.9242053789731052, 'support': 193}, '1': {'precision': 0.8787878787878788, 'recall': 0.5178571428571429, 'f1-score': 0.651685393258427, 'support': 56}, 'accuracy': 0.8755020080321285, 'macro avg': {'precision': 0.8768939393939394, 'recall': 0.7485658771280533, 'f1-score': 0.7879453861157661, 'support': 249}, 'weighted avg': {'precision': 0.8758518924181575, 'recall': 0.8755020080321285, 'f1-score': 0.8629157436316514, 'support': 249}}\n================================================\nj = 1 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [550/550 04:47, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.451400</td>\n      <td>0.244274</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.260400</td>\n      <td>0.290427</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.163800</td>\n      <td>0.217293</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.105700</td>\n      <td>0.192081</td>\n      <td>0.838710</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.070800</td>\n      <td>0.237705</td>\n      <td>0.779661</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.049700</td>\n      <td>0.214500</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.029400</td>\n      <td>0.195643</td>\n      <td>0.819672</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.020300</td>\n      <td>0.242913</td>\n      <td>0.847458</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.016000</td>\n      <td>0.265608</td>\n      <td>0.827586</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.015500</td>\n      <td>0.260398</td>\n      <td>0.827586</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 1 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [550/550 04:47, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.382100</td>\n      <td>0.273608</td>\n      <td>0.780488</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.236500</td>\n      <td>0.279987</td>\n      <td>0.640000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.195000</td>\n      <td>0.277815</td>\n      <td>0.692308</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.093200</td>\n      <td>0.225346</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.059700</td>\n      <td>0.242331</td>\n      <td>0.785714</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.042800</td>\n      <td>0.224261</td>\n      <td>0.843750</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.027100</td>\n      <td>0.244168</td>\n      <td>0.861538</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.020300</td>\n      <td>0.326134</td>\n      <td>0.785714</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.013400</td>\n      <td>0.282262</td>\n      <td>0.827586</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.012800</td>\n      <td>0.290719</td>\n      <td>0.827586</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_1/checkpoint-330']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9794344473007712, 'recall': 0.9292682926829269, 'f1-score': 0.9536921151439298, 'support': 410}, '1': {'precision': 0.49122807017543857, 'recall': 0.7777777777777778, 'f1-score': 0.6021505376344085, 'support': 36}, 'accuracy': 0.9170403587443946, 'macro avg': {'precision': 0.7353312587381049, 'recall': 0.8535230352303523, 'f1-score': 0.7779213263891691, 'support': 446}, 'weighted avg': {'precision': 0.9400276545283229, 'recall': 0.9170403587443946, 'f1-score': 0.9253165618023541, 'support': 446}}\n================================================\nj = 2 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [620/620 05:11, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.408800</td>\n      <td>0.266024</td>\n      <td>0.114286</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.196900</td>\n      <td>0.194417</td>\n      <td>0.701754</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.116900</td>\n      <td>0.227010</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.078500</td>\n      <td>0.251812</td>\n      <td>0.746269</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.058500</td>\n      <td>0.255355</td>\n      <td>0.813559</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.036400</td>\n      <td>0.257230</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.030400</td>\n      <td>0.275051</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.019100</td>\n      <td>0.296845</td>\n      <td>0.806452</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.011500</td>\n      <td>0.318991</td>\n      <td>0.806452</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.009300</td>\n      <td>0.321908</td>\n      <td>0.806452</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 2 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [620/620 05:03, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.335600</td>\n      <td>0.240589</td>\n      <td>0.687500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.165900</td>\n      <td>0.214878</td>\n      <td>0.698413</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.084500</td>\n      <td>0.346611</td>\n      <td>0.727273</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.047400</td>\n      <td>0.353671</td>\n      <td>0.793651</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.019000</td>\n      <td>0.363801</td>\n      <td>0.812500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.009400</td>\n      <td>0.389613</td>\n      <td>0.819672</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.003000</td>\n      <td>0.401410</td>\n      <td>0.825397</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000500</td>\n      <td>0.424756</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000400</td>\n      <td>0.424813</td>\n      <td>0.825397</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000300</td>\n      <td>0.427270</td>\n      <td>0.825397</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_1/checkpoint-124']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9367088607594937, 'recall': 0.9548387096774194, 'f1-score': 0.9456869009584665, 'support': 155}, '1': {'precision': 0.8157894736842105, 'recall': 0.7560975609756098, 'f1-score': 0.7848101265822786, 'support': 41}, 'accuracy': 0.9132653061224489, 'macro avg': {'precision': 0.8762491672218521, 'recall': 0.8554681353265146, 'f1-score': 0.8652485137703725, 'support': 196}, 'weighted avg': {'precision': 0.9114144991774191, 'recall': 0.9132653061224489, 'f1-score': 0.9120341063185496, 'support': 196}}\n================================================\nj = 3 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 05:09, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.394500</td>\n      <td>0.228450</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.194700</td>\n      <td>0.144321</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.119400</td>\n      <td>0.129207</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.064800</td>\n      <td>0.141670</td>\n      <td>0.819672</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.037000</td>\n      <td>0.142054</td>\n      <td>0.885714</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.020800</td>\n      <td>0.141251</td>\n      <td>0.895522</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.016200</td>\n      <td>0.155969</td>\n      <td>0.911765</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.003400</td>\n      <td>0.137407</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.001800</td>\n      <td>0.142369</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.003500</td>\n      <td>0.160218</td>\n      <td>0.911765</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 3 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 05:10, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.333300</td>\n      <td>0.184671</td>\n      <td>0.790123</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.153300</td>\n      <td>0.146778</td>\n      <td>0.823529</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.090000</td>\n      <td>0.158864</td>\n      <td>0.825397</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.040100</td>\n      <td>0.226351</td>\n      <td>0.779661</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.019700</td>\n      <td>0.200702</td>\n      <td>0.861538</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.015300</td>\n      <td>0.208996</td>\n      <td>0.861538</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.011200</td>\n      <td>0.190587</td>\n      <td>0.911765</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.003700</td>\n      <td>0.185720</td>\n      <td>0.911765</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000400</td>\n      <td>0.196025</td>\n      <td>0.911765</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.004300</td>\n      <td>0.200181</td>\n      <td>0.911765</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_0/checkpoint-189']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9, 'recall': 0.9, 'f1-score': 0.9, 'support': 150}, '1': {'precision': 0.5454545454545454, 'recall': 0.5454545454545454, 'f1-score': 0.5454545454545454, 'support': 33}, 'accuracy': 0.8360655737704918, 'macro avg': {'precision': 0.7227272727272727, 'recall': 0.7227272727272727, 'f1-score': 0.7227272727272727, 'support': 183}, 'weighted avg': {'precision': 0.8360655737704918, 'recall': 0.8360655737704918, 'f1-score': 0.8360655737704918, 'support': 183}}\n================================================\nj = 4 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [610/610 05:00, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.428400</td>\n      <td>0.263405</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217000</td>\n      <td>0.200437</td>\n      <td>0.769231</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.127400</td>\n      <td>0.212772</td>\n      <td>0.845070</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.081200</td>\n      <td>0.237986</td>\n      <td>0.810811</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.054700</td>\n      <td>0.255153</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.035400</td>\n      <td>0.296339</td>\n      <td>0.828571</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.033200</td>\n      <td>0.296149</td>\n      <td>0.840580</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.026200</td>\n      <td>0.334831</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.019500</td>\n      <td>0.301777</td>\n      <td>0.840580</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.017600</td>\n      <td>0.303121</td>\n      <td>0.840580</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 4 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [610/610 05:08, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.362900</td>\n      <td>0.205780</td>\n      <td>0.805556</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.185200</td>\n      <td>0.187459</td>\n      <td>0.816901</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.150400</td>\n      <td>0.196162</td>\n      <td>0.821918</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.084100</td>\n      <td>0.269815</td>\n      <td>0.811594</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.048500</td>\n      <td>0.265896</td>\n      <td>0.794521</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.028600</td>\n      <td>0.334170</td>\n      <td>0.815789</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.019900</td>\n      <td>0.366036</td>\n      <td>0.805556</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.014300</td>\n      <td>0.369834</td>\n      <td>0.794521</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.011700</td>\n      <td>0.387099</td>\n      <td>0.794521</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.011300</td>\n      <td>0.395375</td>\n      <td>0.794521</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_0/checkpoint-122']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9861111111111112, 'recall': 0.9466666666666667, 'f1-score': 0.9659863945578231, 'support': 225}, '1': {'precision': 0.5714285714285714, 'recall': 0.8421052631578947, 'f1-score': 0.6808510638297872, 'support': 19}, 'accuracy': 0.9385245901639344, 'macro avg': {'precision': 0.7787698412698413, 'recall': 0.8943859649122807, 'f1-score': 0.8234187291938051, 'support': 244}, 'weighted avg': {'precision': 0.9538202576112412, 'recall': 0.9385245901639344, 'f1-score': 0.9437832335585087, 'support': 244}}\n================================================\nj = 5 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [620/620 05:04, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.393400</td>\n      <td>0.343468</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.226700</td>\n      <td>0.259288</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.135800</td>\n      <td>0.237176</td>\n      <td>0.721311</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.083800</td>\n      <td>0.308596</td>\n      <td>0.718750</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.046600</td>\n      <td>0.454303</td>\n      <td>0.553191</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.047800</td>\n      <td>0.370735</td>\n      <td>0.724138</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.027500</td>\n      <td>0.372007</td>\n      <td>0.701754</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.016100</td>\n      <td>0.379354</td>\n      <td>0.774194</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.015100</td>\n      <td>0.389074</td>\n      <td>0.761905</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.010800</td>\n      <td>0.389183</td>\n      <td>0.786885</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 5 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [620/620 04:56, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.339200</td>\n      <td>0.229146</td>\n      <td>0.757576</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.181100</td>\n      <td>0.177197</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.132000</td>\n      <td>0.246823</td>\n      <td>0.655172</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.071000</td>\n      <td>0.283470</td>\n      <td>0.745763</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.036700</td>\n      <td>0.306961</td>\n      <td>0.716981</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.016000</td>\n      <td>0.374809</td>\n      <td>0.758621</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.008700</td>\n      <td>0.371717</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.001100</td>\n      <td>0.381511</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.001000</td>\n      <td>0.379441</td>\n      <td>0.774194</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000300</td>\n      <td>0.377712</td>\n      <td>0.800000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_0/checkpoint-186']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9424460431654677, 'recall': 0.9290780141843972, 'f1-score': 0.9357142857142857, 'support': 141}, '1': {'precision': 0.8, 'recall': 0.8333333333333334, 'f1-score': 0.816326530612245, 'support': 48}, 'accuracy': 0.9047619047619048, 'macro avg': {'precision': 0.8712230215827339, 'recall': 0.8812056737588653, 'f1-score': 0.8760204081632654, 'support': 189}, 'weighted avg': {'precision': 0.9062692702980474, 'recall': 0.9047619047619048, 'f1-score': 0.905393586005831, 'support': 189}}\n================================================\nj = 6 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [610/610 05:02, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.391700</td>\n      <td>0.159547</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.199300</td>\n      <td>0.147524</td>\n      <td>0.830769</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.122000</td>\n      <td>0.145484</td>\n      <td>0.862069</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.096500</td>\n      <td>0.217888</td>\n      <td>0.823529</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.055600</td>\n      <td>0.196248</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.047000</td>\n      <td>0.213442</td>\n      <td>0.852941</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.030200</td>\n      <td>0.192747</td>\n      <td>0.878788</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.014900</td>\n      <td>0.162542</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.011500</td>\n      <td>0.186886</td>\n      <td>0.875000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.008700</td>\n      <td>0.182757</td>\n      <td>0.875000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 6 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [610/610 05:03, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.351200</td>\n      <td>0.261611</td>\n      <td>0.745098</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217400</td>\n      <td>0.180426</td>\n      <td>0.807018</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.164700</td>\n      <td>0.183694</td>\n      <td>0.793103</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.108400</td>\n      <td>0.282880</td>\n      <td>0.761905</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.082900</td>\n      <td>0.302328</td>\n      <td>0.793103</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.053400</td>\n      <td>0.368824</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.064200</td>\n      <td>0.452599</td>\n      <td>0.788732</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.054500</td>\n      <td>0.280555</td>\n      <td>0.806452</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.037000</td>\n      <td>0.362015</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.032500</td>\n      <td>0.376566</td>\n      <td>0.800000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_0/checkpoint-183']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.8833333333333333, 'recall': 0.8983050847457628, 'f1-score': 0.8907563025210085, 'support': 177}, '1': {'precision': 0.71875, 'recall': 0.6865671641791045, 'f1-score': 0.7022900763358778, 'support': 67}, 'accuracy': 0.8401639344262295, 'macro avg': {'precision': 0.8010416666666667, 'recall': 0.7924361244624336, 'f1-score': 0.7965231894284431, 'support': 244}, 'weighted avg': {'precision': 0.838140368852459, 'recall': 0.8401639344262295, 'f1-score': 0.8390053305767307, 'support': 244}}\n================================================\nj = 7 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 05:03, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.401300</td>\n      <td>0.249689</td>\n      <td>0.761905</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.183300</td>\n      <td>0.217528</td>\n      <td>0.805195</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.123800</td>\n      <td>0.192972</td>\n      <td>0.788732</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.102800</td>\n      <td>0.258153</td>\n      <td>0.746269</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.055200</td>\n      <td>0.243431</td>\n      <td>0.810811</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.032900</td>\n      <td>0.238664</td>\n      <td>0.840580</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.018700</td>\n      <td>0.258562</td>\n      <td>0.831169</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.017500</td>\n      <td>0.260771</td>\n      <td>0.845070</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.014000</td>\n      <td>0.260806</td>\n      <td>0.849315</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.010700</td>\n      <td>0.260407</td>\n      <td>0.861111</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 7 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 04:55, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.387200</td>\n      <td>0.335163</td>\n      <td>0.557377</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.219500</td>\n      <td>0.233412</td>\n      <td>0.759494</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.131700</td>\n      <td>0.300862</td>\n      <td>0.777778</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.067700</td>\n      <td>0.280105</td>\n      <td>0.810811</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.031300</td>\n      <td>0.278824</td>\n      <td>0.805556</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.020400</td>\n      <td>0.328221</td>\n      <td>0.828571</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.015100</td>\n      <td>0.381168</td>\n      <td>0.820513</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.005200</td>\n      <td>0.347868</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.002500</td>\n      <td>0.388156</td>\n      <td>0.794118</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000700</td>\n      <td>0.371822</td>\n      <td>0.794118</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_0/checkpoint-189']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9753086419753086, 'recall': 0.9813664596273292, 'f1-score': 0.978328173374613, 'support': 161}, '1': {'precision': 0.5714285714285714, 'recall': 0.5, 'f1-score': 0.5333333333333333, 'support': 8}, 'accuracy': 0.9585798816568047, 'macro avg': {'precision': 0.7733686067019401, 'recall': 0.7406832298136645, 'f1-score': 0.7558307533539732, 'support': 169}, 'weighted avg': {'precision': 0.9561900587541613, 'recall': 0.9585798816568047, 'f1-score': 0.9572633288756176, 'support': 169}}\n================================================\nj = 8 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 05:11, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.403400</td>\n      <td>0.249179</td>\n      <td>0.746269</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.192700</td>\n      <td>0.273087</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.118400</td>\n      <td>0.199408</td>\n      <td>0.779221</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.070600</td>\n      <td>0.302100</td>\n      <td>0.777778</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.049000</td>\n      <td>0.286571</td>\n      <td>0.794118</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.023000</td>\n      <td>0.349207</td>\n      <td>0.777778</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.016000</td>\n      <td>0.399351</td>\n      <td>0.767123</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.019800</td>\n      <td>0.392731</td>\n      <td>0.788732</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.004700</td>\n      <td>0.419809</td>\n      <td>0.767123</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.002700</td>\n      <td>0.428397</td>\n      <td>0.767123</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 8 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 05:19, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.350100</td>\n      <td>0.226256</td>\n      <td>0.756098</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.174500</td>\n      <td>0.215348</td>\n      <td>0.756757</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.112100</td>\n      <td>0.310999</td>\n      <td>0.746988</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.049300</td>\n      <td>0.302379</td>\n      <td>0.783784</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.031200</td>\n      <td>0.328541</td>\n      <td>0.788732</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.014200</td>\n      <td>0.373887</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.007000</td>\n      <td>0.452932</td>\n      <td>0.789474</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.005800</td>\n      <td>0.469499</td>\n      <td>0.794521</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000400</td>\n      <td>0.498764</td>\n      <td>0.794521</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000400</td>\n      <td>0.502946</td>\n      <td>0.794521</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_0/checkpoint-189']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"{'0': {'precision': 0.9875, 'recall': 0.9753086419753086, 'f1-score': 0.9813664596273292, 'support': 162}, '1': {'precision': 0.8260869565217391, 'recall': 0.9047619047619048, 'f1-score': 0.8636363636363636, 'support': 21}, 'accuracy': 0.9672131147540983, 'macro avg': {'precision': 0.9067934782608695, 'recall': 0.9400352733686067, 'f1-score': 0.9225014116318464, 'support': 183}, 'weighted avg': {'precision': 0.9689771917320029, 'recall': 0.9672131147540983, 'f1-score': 0.9678564486119723, 'support': 183}}\n================================================\nj = 9 // lr = 2e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [600/600 04:57, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.424200</td>\n      <td>0.219639</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.206100</td>\n      <td>0.095052</td>\n      <td>0.852459</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.116000</td>\n      <td>0.097259</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.069700</td>\n      <td>0.137188</td>\n      <td>0.882353</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.026900</td>\n      <td>0.138549</td>\n      <td>0.895522</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.014100</td>\n      <td>0.106275</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.010000</td>\n      <td>0.117325</td>\n      <td>0.918033</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.003700</td>\n      <td>0.118759</td>\n      <td>0.935484</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.001200</td>\n      <td>0.129425</td>\n      <td>0.918033</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.001200</td>\n      <td>0.150753</td>\n      <td>0.918033</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"================================================\nj = 9 // lr = 5e-05\n================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [600/600 04:47, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.372600</td>\n      <td>0.161894</td>\n      <td>0.816901</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.180200</td>\n      <td>0.110980</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.132400</td>\n      <td>0.091577</td>\n      <td>0.906250</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.060000</td>\n      <td>0.085825</td>\n      <td>0.898551</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.041000</td>\n      <td>0.095063</td>\n      <td>0.927536</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.015900</td>\n      <td>0.149478</td>\n      <td>0.885246</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.015400</td>\n      <td>0.240069</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.010900</td>\n      <td>0.250803</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.009000</td>\n      <td>0.231970</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.008700</td>\n      <td>0.166327</td>\n      <td>0.885246</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"['my_checkpoint_1/checkpoint-240']\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'0': {'precision': 0.9705882352941176, 'recall': 0.7983870967741935, 'f1-score': 0.8761061946902654, 'support': 248}, '1': {'precision': 0.40476190476190477, 'recall': 0.85, 'f1-score': 0.5483870967741935, 'support': 40}, 'accuracy': 0.8055555555555556, 'macro avg': {'precision': 0.6876750700280112, 'recall': 0.8241935483870968, 'f1-score': 0.7122466457322294, 'support': 288}, 'weighted avg': {'precision': 0.8920012449424214, 'recall': 0.8055555555555556, 'f1-score': 0.8305896533130332, 'support': 288}}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Aquí acaba el código de colab. Falta hacer el zip para poder descargar los resultados (y opcionalmente usar el bot para que me avise del final de la ejecución)","metadata":{}},{"cell_type":"code","source":"import requests\n\n# Definir la URL base y los parámetros\nurl = \"https://api.callmebot.com/whatsapp.php\"\nparams = {\n    \"phone\": \"+34653508040\",\n    \"apikey\": \"1512070\",\n    \"text\": \"🤖¡Ejecución terminada! 🤖\\nVe a echarle un vistazo ☝🤓\"\n}\n\n# Enviar la solicitud GET\nresponse = requests.get(url, params=params)\n\n# Imprimir el estado de la respuesta\nprint(response.status_code)\nprint(response.text)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T11:41:25.236880Z","iopub.execute_input":"2024-08-04T11:41:25.237209Z","iopub.status.idle":"2024-08-04T11:41:25.819180Z","shell.execute_reply.started":"2024-08-04T11:41:25.237181Z","shell.execute_reply":"2024-08-04T11:41:25.818229Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"200\n<p>Message to: +34653508040<p>Text to send: 🤖¡Ejecución terminada! 🤖%0AVe a echarle un vistazo ☝🤓<p><b>Message queued.</b> You will receive it in a few seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r results_docs_bert.zip results_docs_bert\nfrom IPython.display import FileLink \nFileLink(r'results_docs_bert.zip')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T11:46:06.064530Z","iopub.execute_input":"2024-08-04T11:46:06.064911Z","iopub.status.idle":"2024-08-04T11:46:07.116749Z","shell.execute_reply.started":"2024-08-04T11:46:06.064875Z","shell.execute_reply":"2024-08-04T11:46:07.115618Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"updating: results_docs_deberta/ (stored 0%)\nupdating: results_docs_deberta/res_docs_deberta_8.txt (deflated 57%)\nupdating: results_docs_deberta/res_docs_deberta_7.txt (deflated 57%)\nupdating: results_docs_deberta/res_docs_deberta_9.txt (deflated 58%)\nupdating: results_docs_deberta/res_docs_deberta_3.txt (deflated 67%)\nupdating: results_docs_deberta/res_docs_deberta_2.txt (deflated 56%)\nupdating: results_docs_deberta/res_docs_deberta_1.txt (deflated 57%)\nupdating: results_docs_deberta/res_docs_deberta_5.txt (deflated 58%)\nupdating: results_docs_deberta/res_docs_deberta_0.txt (deflated 57%)\nupdating: results_docs_deberta/res_docs_deberta_6.txt (deflated 57%)\nupdating: results_docs_deberta/res_docs_deberta_4.txt (deflated 58%)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/results_docs_deberta.zip","text/html":"<a href='results_docs_deberta.zip' target='_blank'>results_docs_deberta.zip</a><br>"},"metadata":{}}]}]}