{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown -U\n!pip install evaluate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"]=\"true\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p results_bert","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown '1pl9hGX3_4lMJvl4thbwkEXRCTi_dH1au'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aqui empiezo el código igual al de colab","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FILE_REQ='/kaggle/working/ReWoRC_Dataset_req.csv'\ndata_req = load_dataset('csv', data_files=FILE_REQ, sep=';')\nprint(data_req['train']['NFR'][21])\n\ndef create_labels(row):\n  return {'labels': 'F' if row['NFR'] == 'Funcional' else 'NF'}\n\ndata_req = data_req.map(create_labels)\ndata_req = data_req.class_encode_column('labels')\nprint(set(data_req['train']['labels']))\ndata_req = data_req['train']\ndata_req.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n#BERT: model_name = 'google-bert/bert-base-cased'\n#DEBERTA: model_name = 'microsoft/deberta-v3-base'\n#ROBERTA: model_name = 'FacebookAI/roberta-base'\nmodel_name = 'google-bert/bert-base-cased' # modificar con el modelo que queramos cada vez","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_text(row, tokenizer):\n  row_encode = tokenizer(row['Requisito'], truncation=True)\n  return row_encode\n\n\nencode_data = data_req.map(encode_text, fn_kwargs={'tokenizer':tokenizer})\nencode_data\n\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\nfolds = StratifiedKFold(n_splits=10, shuffle=True)\n\nsplits = folds.split(np.zeros(data_req.num_rows), encode_data[\"labels\"])\ntest_sets = []\ntrain_val_sets = []\ni=1\nfor train_val_idxs, test_idxs in splits:\n  print (i)\n  print(test_idxs)\n  print('*******')\n  data_test = encode_data.select(test_idxs)\n  data_train = encode_data.select(train_val_idxs)\n  data_train_val = data_train.train_test_split(train_size=0.9, stratify_by_column='labels')\n  #data_train_inner, data_val_inner = data_train.train_test_split(train_size=0.9)\n  test_sets.append(data_test)\n  train_val_sets.append(data_train_val)\n  i = i + 1\n\nprint(test_sets[0])\nprint(train_val_sets[0]['test'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis = 1)\n    return metric.compute(predictions=predictions, references=labels)\n\n# load metric\nmetric_name = 'f1'\nmetric = evaluate.load(metric_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si uso dos GPUs poner batch size 16, porque van 16 a cada una = 32","metadata":{}},{"cell_type":"code","source":"import glob\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import classification_report\n\nlr_values =[2e-5, 5e-5]\n\nfor j in range(len(train_val_sets)):\n    best_lr = -1\n    best_f1 = -1\n\n    # para escribir los resultados\n    with open(f'results_bert/res_bert_{j}.txt', 'w') as f:\n    # NOTA: si no va, deshacer el tab extra del siguiente bucle for\n      for i, lr in enumerate(lr_values):\n        print(\"================================================\")\n        print(\"j = \" + str(j) + \" // lr = \" + str(lr))\n        print(\"================================================\")\n      # argumentos para el entrenamiento\n        training_args = TrainingArguments(\n            #output_dir=\"my_checkpoint\"+str(j),\n            output_dir=f\"my_checkpoint_{i}\",\n            overwrite_output_dir = True,\n            num_train_epochs=10,\n            #para probar tanto promise como nuestro coger 10 epochs\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            save_total_limit = 1,\n            load_best_model_at_end=True,\n            logging_strategy='epoch',\n            optim=\"adamw_torch\",\n            per_device_train_batch_size=32,\n            #lo dejaremos en 32: per_device_eval_batch_size=32,\n            learning_rate=lr,\n            #probar tanto 2e-5 como 5e-5\n            weight_decay=0.01,\n        )\n\n        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n        # declarar el \"entrenador\"\n        trainer = Trainer(\n            model=model,\n            args=training_args,\n            train_dataset=train_val_sets[j]['train'],\n            eval_dataset=train_val_sets[j]['test'],\n            tokenizer=tokenizer,\n            compute_metrics=compute_metrics\n        )\n\n        # realizar el entrenamiento\n        trainer.train()\n\n        out_pred = trainer.predict(train_val_sets[j]['test'])\n        if out_pred.metrics['test_f1'] > best_f1:\n          best_f1 = out_pred.metrics['test_f1']\n          best_lr = i\n      # cargar el mejor modelo y resultados para test\n      best_dir = glob.glob(f\"my_checkpoint_{best_lr}/checkpoint*\")\n      print(best_dir)\n      model_best = AutoModelForSequenceClassification.from_pretrained(best_dir[0])\n      trainer_best = Trainer(\n            model=model_best,\n            args=None,\n            train_dataset=None,\n            eval_dataset=None,\n            tokenizer=tokenizer,\n            compute_metrics=compute_metrics\n        )\n\n      test_data = test_sets[j]\n      outputs_pred = trainer_best.predict(test_dataset=test_data)\n\n      # model predictions\n      predictions = np.argmax(outputs_pred.predictions, axis=1)\n\n      #d_res = classification_report(test_data['labels'], predictions, digits=3, return_dict = True)\n      d_res = classification_report(test_data['labels'], predictions, digits=3, output_dict=True)\n      print(d_res)\n      f.write(\"================== Best lr ================\\n\")\n      f.write(str(best_lr))\n      f.write(\"\\n\")\n      f.write( \"================== Resultados ================\\n\")\n      f.write(str(d_res))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aquí acaba el código de colab. \nFalta hacer el zip para poder descargar los resultados (y opcionalmente usar el bot para que me avise del final de la ejecución)","metadata":{}},{"cell_type":"code","source":"import requests\n\n# Definir la URL base y los parámetros\nurl = \"https://api.callmebot.com/whatsapp.php\"\nparams = {\n    \"phone\": \"+34653508040\",\n    \"apikey\": \"1512070\",\n    \"text\": \"🤖¡Ejecución terminada! 🤖\\nVe a echarle un vistazo ☝🤓\"\n}\n\n# Enviar la solicitud GET\nresponse = requests.get(url, params=params)\n\n# Imprimir el estado de la respuesta\nprint(response.status_code)\nprint(response.text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r results_bert.zip results_bert\nfrom IPython.display import FileLink \nFileLink(r'results_bert.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}