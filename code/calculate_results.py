# -*- coding: utf-8 -*-
"""calculate_results.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DHziW6mNe1bh4jWKSxJx2k_gN-T12Moi
"""

import ast
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""CASOS:

---

BERT stratified: *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/BERT/results_bert/res_bert_'*

---

BERT temas: *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/BERT/results_temas_bert/res_temas_bert_'*

---

BERT docs:  *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/BERT/results_docs_bert/res_docs_bert_'*

---

DEBERTA stratified: *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/DEBERTA/results_deberta/res_deberta_'*

---


DEBERTA temas: *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/DEBERTA/results_temas_deberta/res_temas_deberta_'*

---


DEBERTA docs:  *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/DEBERTA/results_docs_deberta/res_docs_deberta_'*

---

ROBERTA stratified: *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/ROBERTA/results_roberta/res_roberta_'*

---

ROBERTA temas: *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/ROBERTA/results_temas_roberta/res_temas_roberta_'*

---

ROBERTA docs:  *FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/ROBERTA/results_docs_roberta/res_docs_roberta_'*

---

"""

# the directory where we can find the .txt results may change
FILE_NAME_PREFIX = '/content/drive/MyDrive/TFG/RESULTADOS/ROBERTA/results_promise_stratified_roberta/res_roberta_'
f1_score_1 = []
precision_1 = []
recall_1 = []
f1_score_0 = []
precision_0 = []
recall_0 = []
best_lr_array = []
for i in range(10): # si hacemos la comprobación de temas "for i in range(6):"
  f_name = FILE_NAME_PREFIX+str(i)+'.txt'
  print(f_name)
  f_in = open(f_name,'r')
  lines = f_in.readlines()
  best_lr = int(lines[1])
  dict_res_string = lines[3]
  dict_res = ast.literal_eval(dict_res_string)
  f_in.close()
  f1_score_1.append(dict_res['1']['f1-score'])
  precision_1.append(dict_res['1']['precision'])
  recall_1.append(dict_res['1']['recall'])
  # para los ficheros results_promise_docs_roberta/...7 y results_promise_docs_roberta/...8 no hay ['0']
  # esto se debe a que las particiones correspondientes debían ser todo 1s
  # para debuggear esto debería repetir la ejecución o lo que voy a hacer a continuación:
  if '0' in dict_res:
    f1_score_0.append(dict_res['0']['f1-score'])
    precision_0.append(dict_res['0']['precision'])
    recall_0.append(dict_res['0']['recall'])
  best_lr_array.append(best_lr)
  print(precision_1)

# para comparar con otro LM: cargarlo y hacer t-test
# the directory where we can find the .txt results may change
FILE_NAME_PREFIX_2 = '/content/drive/MyDrive/TFG/RESULTADOS/ROBERTA/results_roberta/res_roberta_'
f1_score_1_2 = []
precision_1_2 = []
recall_1_2 = []
f1_score_0_2 = []
precision_0_2 = []
recall_0_2 = []
best_lr_array_2 = []
for i in range(10): # si hacemos la comprobación de temas "for i in range(6):"
  f_name = FILE_NAME_PREFIX_2+str(i)+'.txt'
  print(f_name)
  f_in = open(f_name,'r')
  lines = f_in.readlines()
  best_lr = int(lines[1])
  dict_res_string = lines[3]
  dict_res = ast.literal_eval(dict_res_string)
  f_in.close()
  f1_score_1_2.append(dict_res['1']['f1-score'])
  precision_1_2.append(dict_res['1']['precision'])
  recall_1_2.append(dict_res['1']['recall'])
  if '0' in dict_res:
   f1_score_0_2.append(dict_res['0']['f1-score'])
   precision_0_2.append(dict_res['0']['precision'])
   recall_0_2.append(dict_res['0']['recall'])
  best_lr_array_2.append(best_lr)
  print(f1_score_1_2)

print(precision_0)
print(precision_0_2)

# comprobación de que la variación es influyente
import scipy
ttest_precision_0=scipy.stats.ttest_ind(precision_0, precision_0_2)
ttest_pre_0=ttest_precision_0.pvalue
ttest_recall_0=scipy.stats.ttest_ind(recall_0, recall_0_2)
ttest_rec_0=ttest_recall_0.pvalue
ttest_f1score_0=scipy.stats.ttest_ind(f1_score_0, f1_score_0_2)
ttest_f1s_0=ttest_f1score_0.pvalue
ttest_precision_1=scipy.stats.ttest_ind(precision_1, precision_1_2)
ttest_pre_1=ttest_precision_1.pvalue
ttest_recall_1=scipy.stats.ttest_ind(recall_1, recall_1_2)
ttest_rec_1=ttest_recall_1.pvalue
ttest_f1score_1=scipy.stats.ttest_ind(f1_score_1, f1_score_1_2)
ttest_f1s_1=ttest_f1score_1.pvalue
if ttest_pre_1 > 0.05:
    print(f"La variación en la precision de '1' no es significativa, p-valor = {ttest_pre_1}")
else:
    print(f"¡¡OJO!! La variación en la precision de '1' es significativa, p-valor = {ttest_pre_1}")
if ttest_rec_1 > 0.05:
    print(f"La variación en el recall de '1' no es significativa, p-valor = {ttest_rec_1}")
else:
    print(f"¡¡OJO!! La variación en el recall de '1' es significativa, p-valor = {ttest_rec_1}")
if ttest_f1s_1 > 0.05:
    print(f"La variación en el f1-score de '1' no es significativa, p-valor = {ttest_f1s_1}")
else:
    print(f"¡¡OJO!! La variación en el f1-score de '1' es significativa, p-valor = {ttest_f1s_1}")


if ttest_pre_0 > 0.05:
    print(f"La variación en la precision de '0' no es significativa, p-valor = {ttest_pre_0}")
else:
    print(f"¡¡OJO!! La variación en la precision de '0' es significativa, p-valor = {ttest_pre_0}")
if ttest_rec_0 > 0.05:
    print(f"La variación en el recall de '0' no es significativa, p-valor = {ttest_rec_0}")
else:
    print(f"¡¡OJO!! La variación en el recall de '0' es significativa, p-valor = {ttest_rec_0}")
if ttest_f1s_0 > 0.05:
    print(f"La variación en el f1-score de '0' no es significativa, p-valor = {ttest_f1s_0}")
else:
    print(f"¡¡OJO!! La variación en el f1-score de '0' es significativa, p-valor = {ttest_f1s_0}")

media_f1_1 = np.mean(f1_score_1)
media_precision_1 = np.mean(precision_1)
media_recall_1 = np.mean(recall_1)
media_f1_0 = np.mean(f1_score_0)
media_precision_0 = np.mean(precision_0)
media_recall_0 = np.mean(recall_0)
print(f"La media de las f1-score de los 1s es: {media_f1_1}")
print(f"La media de las precisiones de los 1s es: {media_precision_1}")
print(f"La media de las recalls de los 1s es: {media_recall_1}")
print(f"La media de las f1-score de los 0s es: {media_f1_0}")
print(f"La media de las precisiones de los 0s es: {media_precision_0}")
print(f"La media de las recalls de los 0s es: {media_recall_0}")

std_f1_1 = np.std(f1_score_1)
std_precision_1 = np.std(precision_1)
std_recall_1 = np.std(recall_1)
std_f1_0 = np.std(f1_score_0)
std_precision_0 = np.std(precision_0)
std_recall_0 = np.std(recall_0)
print(f"La desviación estándar de las f1-score de los 1s es: {std_f1_1}")
print(f"La desviación estándar de las precisiones de los 1s es: {std_precision_1}")
print(f"La desviación estándar de las recalls de los 1s es: {std_recall_1}")
print(f"La desviación estándar de las f1-score de los 0s es: {std_f1_0}")
print(f"La desviación estándar de las precisiones de los 0s es: {std_precision_0}")
print(f"La desviación estándar de las recalls de los 0s es: {std_recall_0}")

numero_de_unos = best_lr_array.count(1)
numero_de_ceros = best_lr_array.count(0)
print(f"Es mejor escoger un learning rate de 2e-5 en {numero_de_ceros} casos.")
print(f"Es mejor escoger un learning rate de 5e-5 en {numero_de_unos} casos.")

from scipy.stats import shapiro
data = [precision_1_2]

# 1. Prueba de Shapiro-Wilk
stat, p = shapiro(data)
print(f"Estadístico de Shapiro-Wilk: {stat}, p-valor: {p}")
if p > 0.01:
    print("Los datos parecen seguir una distribución normal.")
else:
    print("Los datos no parecen seguir una distribución normal.")

# Comprobar diferencia de varianzas
from scipy.stats import levene

# Prueba de Levene para igualdad de varianzas
stat, p_value = levene(recall_0, recall_0_2)

print(f"Estadístico de Levene: {stat}, p-valor: {p_value}")

if p_value < 0.01:
    print("Las varianzas son significativamente diferentes.")
else:
    print("No hay evidencia para decir que las varianzas son diferentes.")